[{"title": "A Deep Learning Approach to Locate Buggy Files", "authors": "Jiang Bo, Liu Pengfei, Xu Jie", "year": 2020, "classification": "Learning-based bug localization", "tags": ["deep learning"], "links": "https://doi.org/10.1109/DESSERT50317.2020.9125003", "CCF": "\u672a\u77e5", "conference": "DESSERT", "abstract": "Bug localization, using a bug description to locate potential buggy source code files automatically, can assist developers to quick fix bugs and relieve maintaining costs for industry. Traditional models are mainly based on information retrieval (IR) techniques, employing the lexical similarity between code and text to locate potential buggy files. Recent researches involve deep learning techniques, utilizing a neural network based encoder to extract semantics from both code and text. However, rather than natural language, code contains not only semantic information, but also important relations among classes, functions, and variables. For this purpose, we introduce a deep learning approach with various embedding methods for bug localization, and it achieves competitive performances on two public datasets.", "datasets": ""}, {"title": "A Large-Scale Comparative Evaluation of IR-Based Tools for Bug Localization ", "authors": "Akbar Shayan A., Kak Avinash C.", "year": 2020, "classification": "Empirical study", "tags": ["empirical study", "dataset"], "links": "https://doi.org/10.1145/3379597.3387474", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "MSR", "abstract": "This paper reports on a large-scale comparative evaluation of IR-based tools for automatic bug localization. We have divided the tools in our evaluation into the following three generations: (1) The first-generation tools, now over a decade old, that are based purely on the Bag-of-Words (BoW) modeling of software libraries. (2) The somewhat more recent second-generation tools that augment BoW-based modeling with two additional pieces of information: historical data, such as change history, and structured information such as class names, method names, etc. And, finally, (3) The third-generation tools that are currently the focus of much research and that also exploit proximity, order, and semantic relationships between the terms. It is important to realize that the original authors of all these three generations of tools have mostly tested them on relatively small-sized datasets that typically consisted no more than a few thousand bug reports. Additionally, those evaluations only involved Java code libraries. The goal of the present paper is to present a comprehensive large-scale evaluation of all three generations of bug-localization tools with code libraries in multiple languages. Our study involves over 20,000 bug reports drawn from a diverse collection of Java, C/C++, and Python projects. Our results show that the third-generation tools are significantly superior to the older tools. We also show that the word embeddings generated using code files written in one language are effective for retrieval from code libraries in other languages. KEYWORDS source code search, word embeddings, information retrieval, bug localization ACM Reference Format: Shayan A. Akbar and Avinash C.", "datasets": "https://engineering.purdue.edu/RVL/Bugzbook/"}, {"title": "BuGL - A Cross-Language Dataset for Bug Localization", "authors": "Muvva Sandeep, Rao A Eashaan, Chimalakonda Sridhar", "year": 2020, "classification": "Datasets", "tags": ["dataset", "cross-language"], "links": "http://arxiv.org/abs/2004.08846", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Bug Localization is the process of locating potential error-prone files or methods from a given bug report and source code. There is extensive research on bug localization in the literature that focuses on applying information retrieval techniques or machine learn- ing/deep learning approaches or both, to detect location of bugs. The common premise for all approaches is the availability of a good dataset, which in this case, is the standard benchmark dataset that comprises of 6 Java projects and in some cases, more than 6 Java projects. The existing dataset do not comprise projects of other programming languages, despite of the need to investigate specific and cross project bug localization. To the best of our knowledge, we are not aware of any dataset that addresses this concern. In this paper, we present BuGL, a large-scale cross-language dataset. BuGL constitutes ofmore than 10,000 bug reports drawn from open- source projects written in four programming languages, namely C, C++, Java, and Python. The dataset consists of information which includes Bug Reports and Pull-Requests. BuGL aims to unfold new research opportunities in the area of bug localization.", "datasets": "https: //github.com/muvvasandeep/BuGL"}, {"title": "Control Flow Graph Embedding Based on Multi-Instance Decomposition for Bug Localization", "authors": "Huo Xuan, Li Ming, Zhou Zhi-hua", "year": 2020, "classification": "Learning-based bug localization", "tags": ["CNN", "control flow graph"], "links": "https://doi.org/10.1609/aaai.v34i04.5844", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "AAAI", "abstract": "During software maintenance, bug report is an effective way to identify potential bugs hidden in a software system. It is a great challenge to automatically locate the potential buggy source code according to a bug report. Traditional approaches usually represent bug reports and source code from a lexical perspective to measure their similarities. Recently, some deep learning models are proposed to learn the unified features by exploiting the local and sequential nature, which overcomes the difficulty in modeling the difference between natural and programming languages. However, only considering local and sequential information from one dimension is not enough to represent the semantics, some multi-dimension information such as structural and functional nature that carries additional semantics has not been well-captured. Such information beyond the lexical and structural terms is extremely vital in modeling program functionalities and behaviors, leading to a better representation for identifying buggy source code. In this paper, we propose a novel model named CG-CNN, which is a multi-instance learning framework that enhances the unified features for bug localization by exploiting structural and sequential nature from the control flow graph. Experimental results on widely-used software projects demonstrate the effectiveness of our proposed CG-CNN model.", "datasets": ""}, {"title": "CooBa: Cross-project Bug Localization via Adversarial Transfer Learning", "authors": "Zhu Ziye, Li Yun, Tong Hanghang, Wang Yu", "year": 2020, "classification": "Learning-based bug localization", "tags": ["cross-project", "adversarial transfer learning"], "links": "https://doi.org/10.24963/ijcai.2020/493", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "IJCAI", "abstract": "Bug localization plays an important role in software quality control. Many supervised machine learning models have been developed based on historical bug-fix information. Despite being successful, these methods often require sufficient historical data (i.e., labels), which is not always available especially for newly developed software projects. In response, cross-project bug localization techniques have recently emerged whose key idea is to transferring knowledge from label-rich source project to locate bugs in the target project. However, a major limitation of these existing techniques lies in that they fail to capture the specificity of each individual project, and are thus prone to negative transfer. To address this issue, we propose an adversarial transfer learning bug localization approach, focusing on only transferring the common characteristics (i.e., public information) across projects. Specifically, our approach (CooBa) learns the indicative public information from cross-project bug reports through a shared encoder, and extracts the private information from code files by an individual feature extractor for each project. CooBa further incorporates adversarial learning mechanism to ensure that public information shared between multiple projects could be effectively extracted. Extensive experiments on four large-scale real-world data sets demonstrate that the proposed CooBa significantly outperforms the state of the art techniques.", "datasets": ""}, {"title": "Enhancing supervised bug localization with metadata and stack-trace", "authors": "Wang Yaojing, Yao Yuan, Tong Hanghang, Huo Xuan, Li Ming, Xu Feng, Lu Jian", "year": 2020, "classification": "IR-based bug localization", "tags": ["topic model", "metadata", "stack trace"], "links": "https://doi.org/10.1007/s10115-019-01426-2", "CCF": "B\u7c7b\u671f\u520a", "conference": "KAIS", "abstract": "Locating relevant source files for a given bug report is an important task in software development and maintenance. To make the locating process easier, information retrieval methods have been widely used to compute the content similarities between bug reports and source files. In addition to content similarities, various other sources of information such as the metadata and the stack-trace in the bug report can be used to enhance the localization accuracy. In this paper, we propose a supervised topic modeling approach for automatically locating the relevant source files of a bug report. In our approach, we take into account the following five key observations. First, supervised modeling can effectively make use of the existing fixing histories. Second, certain words in bug reports tend to appear multiple times in their relevant source files. Third, longer source files tend to have more bugs. Fourth, metainformation brings additional guidance on the search space. Fifth, buggy source files could be already contained in the stack-trace. By integrating the above five observations, we experimentally show that the proposed method can achieve up to 67.1% improvement in terms of prediction accuracy over its best competitors and scales linearly with the size of the data.", "datasets": ""}, {"title": "Exploiting Code Knowledge Graph for Bug Localization via Bi-directional Attention", "authors": "Zhang Jinglei, Xie Rui, Ye Wei, Zhang Yuhan, Zhang Shikun", "year": 2020, "classification": "Learning-based bug localization", "tags": ["code knowledge graph", "deep learning"], "links": "https://doi.org/10.1145/3387904.3389281", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICPC", "abstract": "Bug localization automatic localize relevant source files given a natural language description ofbug within a software project. For a large project containing hundreds and thousands of source files, de- velopers need cost lots of time to understand bug reports generated by quality assurance and localize these buggy source files. Tradi- tional methods are heavily depending on the information retrieval technologies which rank the similarity between source files and bug reports in lexical level. Recently, deep learning based models are used to extract semantic information of code with significant im- provements for bug localization. However, programming language is a highly structural and logical language, which contains various relations within and cross source files. Thus, we propose KGBu- gLocator to utilize knowledge graph embeddings to extract these interrelations of code, and a keywords supervised bi-directional attention mechanism regularize model with interactive information between source files and bug reports. With extensive experiments on four different projects, we prove our model can reach the new the-state-of-art(SOTA) for bug localization.", "datasets": ""}, {"title": "LaProb: A Label Propagation-Based Software Bug Localization Method", "authors": "Li Zhengliang, Jiang Zhiwei, Chen Xiang, Cao Kaibo, Gu Qing", "year": 2020, "classification": "IR-based bug localization", "tags": ["label propagation", "biparty hybrid graph"], "links": "https://doi.org/10.1016/j.infsof.2020.106410", "CCF": "B\u7c7b\u671f\u520a", "conference": "IST", "abstract": "Context: Bug localization, which locates suspicious snippets related to the bugs mentioned in the bug reports, is time-consuming and laborious. Many automatic bug localization methods have been proposed to speed up the process of bug fixing and reduce the burden on developers. However, these methods have not fully utilized the intra-relations and inter-relations among the bug reports and the source files (i.e., call relationships between the source files).\nObjective: In this paper, we propose a novel method LaProb (a label propagation-based software bug localization method) that makes full use of the intra-relations and inter-relations among the bug reports and the source files.\nMethod: LaProb transforms the problem of bug localization into a multi-label distribution learning problem. LaProb first constructs a BHG (Biparty Hybrid Graph) by analyzing the structures and contents of bug reports and source files, and calculates the intra-relations between pairs of bug reports and source files, as well as the inter-relations between bug reports and source files. Based on BHG, LaProb then predicts the label distribution on source files by using the label propagation algorithm for the target bug report. Finally, LaProb finishes the bug localization task by sorting the results of label propagation.\nResults: The experimental results on nine open-source software projects (i.e., SWT, AspectJ, Eclipse, ZXing, SEC, HIVE, HBASE, WFLY and ROO) show that compared with several state-of-the-art methods (including BugLocator, BRTracer, BLUiR, AmaLgam, Locus and BLIZZARD), LaProb performs the best in terms of all five metrics on average. For MAP performance measure, LaProb achieves an improvement of 30.9%, 36.6%, 28.0%, 22.2%, 20.1% and 53.5%, respectively.\nConclusion: LaProb is capable of making full use of the intra-relations and inter-relations among the bug reports and the source files and achieves better performance than seven state-of-the-art methods.", "datasets": ""}, {"title": "ManQ: Many-objective optimization-based automatic query reduction for IR-based bug localization", "authors": "Kim Misoo, Lee Eunseok", "year": 2020, "classification": "Query reformulation", "tags": ["query reformulation"], "links": "https://doi.org/10.1016/j.infsof.2020.106334", "CCF": "B\u7c7b\u671f\u520a", "conference": "IST", "abstract": "Context: An information retrieval-based bug localization (IRBL) method is proposed to localize buggy files using a bug report as a query. The performance of this method strongly depends on the quality of the query. However, these queries contain noise terms that hinder their use for IRBL. To improve the quality of a query, an automatic query reduction (AQR) technique that removes noise words from the query is needed. Objective: Our objective is to develop an AQR method for IRBL. Most existing AQR techniques are based on single objective optimization, which presents issues in terms of biased and limited performance. To solve these issues, it is necessary to find a subquery that comprehensively satisfies all of their objectives. Method: We propose an AQR technique called ManQ, which is a many-objective optimization-based AQR method for IRBL. We design 15 objective functions to (1) maintain the query quality properties, (2) maintain the important terms, (3) maintain the initial information, and (4) minimize the query length. ManQ finds a final subquery that maximize the return values of these objective functions. Results: The experimental results show that ManQ improves the quality of poor queries. We also show that if we select the best query among the candidates generated by ManQ, we can increase the number of improved queries by more than 53.4% of all queries. Conclusion: ManQ improves the performance of IRBL by improving the quality of queries through a many-objective optimization approach.", "datasets": ""}, {"title": "Multi-Dimension Convolutional Neural Network for Bug Localization", "authors": "Wang Bei, Xu Ling, Yan Meng, Liu Chao, Liu Ling", "year": 2020, "classification": "Learning-based bug localization", "tags": ["CNN"], "links": "https://doi.org/10.1109/tsc.2020.3006214", "CCF": "B\u7c7b\u671f\u520a", "conference": "TSC", "abstract": "Abstract\u2014Software bugs remain frequent in the life cycle of software development and maintenance. Automatic localization of buggy source code files is critical for timely bug fixing and improving the efficiency of software quality assurance. Various bug localization techniques have been proposed using different dimensions of features. Recent studies have shown that different dimensions of features may play different roles in bug localization. Unfortunately, how to effectively merge these dimensions of features for improving bug localization has rarely been investigated. This paper presents a Multi-Dimension Convolutional Neural Network (MD-CNN) model for bug localization automatically based on a bug report. Our approach has dual-novelty. First, we identify and extract five statistical dimensions of features. Second, we design a Convolutional Neural Network (CNN) model that takes our five statistical dimensions of features as the input and iteratively learns the complex and non-linear relationship between the features and the bug locations. The MD-CNN bug localization model is verified using six large-scale open source projects. The experimental results show that our MD-CNN outperforms the existing representative bug localization techniques in terms of the Mean Average Precision (MAP) and the number of bugs successfully localized in the top 1, 5, and 10 matched source code files", "datasets": ""}, {"title": "On Combining IR Methods to Improve Bug Localization", "authors": "Khatiwada Saket, Tushev Miroslav, Mahmoud Anas", "year": 2020, "classification": "IR-based bug localization", "tags": ["VSM", "LSI", "JSM", "PMI"], "links": "https://doi.org/10.1145/3387904.3389280", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICPC", "abstract": "Information Retrieval (IR) methods have been recently employed to provide automatic support for bug localization tasks. However, for an IR-based bug localization tool to be useful, it has to achieve adequate retrieval accuracy. Lower precision and recall can leave developers with large amounts of incorrect information to wade through. To address this issue, in this paper, we systematically investigate the impact of combining various IR methods on the retrieval accuracy of bug localization engines. The main assumption is that different IR methods, targeting different dimensions of similarity between artifacts, can be used to enhance the confidence in each others\u2019 results. Five benchmark systems from different application domains are used to conduct our analysis. The results show that a) near-optimal global configurations can be determined for different combinations of IR methods, b) optimized IR-hybrids can significantly outperform individual methods as well as other unoptimized methods, and c) hybrid methods achieve their best performance when utilizing information-theoretic IR methods. Our findings can be used to enhance the practicality of IR-based bug localization tools and minimize the cognitive overload developers often face when locating bugs.", "datasets": ""}, {"title": "On the relationship between bug reports and queries for text retrieval-based bug localization", "authors": "Mills Chris, Parra Esteban, Pantiuchina Jevgenija, Bavota Gabriele, Haiduc Sonia", "year": 2020, "classification": "Query reformulation", "tags": ["query reformulation"], "links": "https://doi.org/10.1007/s10664-020-09823-w", "CCF": "B\u7c7b\u671f\u520a", "conference": "ESE", "abstract": "As societal dependence on software continues to grow, bugs are becoming increasingly costly in terms of financial resources as well as human safety. Bug localization is the process by which a developer identifies buggy code that needs to be fixed to make a system safer and more reliable. Unfortunately, manually attempting to locate bugs solely from the information in a bug report requires advanced knowledge of how a system is constructed and the way its constituent pieces interact. Therefore, previous work has investigated numerous techniques for reducing the human effort spent in bug localization. One of the most common approaches is Text Retrieval (TR) in which a system\u2019s source code is indexed into a search space that is then queried for code relevant to a given bug report. In the last decade, dozens of papers have proposed improvements to bug localization using TR with largely positive results. However, several other studies have called the technique into question. According to these studies, evaluations of TR-based approaches often lack sufficient controls on biases that artificially inflate the results, namely: misclassified bugs, tangled commits, and localization hints. Here we argue that contemporary evaluations of TR approaches also include a negative bias that outweighs the previously identified positive biases: while TR approaches expect a natural language query, most evaluations simply formulate this query as the full text of a bug report. In this study we show that highly performing queries can be extracted from the bug report text, in order to make TR effective even without the aforementioned positive biases. Further, we analyze the provenance of terms in these highly performing queries to drive future work in automatic query extraction from bug reports.", "datasets": ""}, {"title": "Scaffle: bug localization on millions of files", "authors": "Pradel Michael, Murali Vijayaraghavan, Qian Rebecca, Machalica Mateusz, Meijer Erik, Chandra Satish", "year": 2020, "classification": "Learning-based bug localization", "tags": ["millions of files"], "links": "https://doi.org/10.1145/3395363.3397356", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ISSTA", "abstract": "Despite all efforts to avoid bugs, software sometimes crashes in the field, leaving crash traces as the only information to localize the problem. Prior approaches on localizing where to fix the root cause of a crash do not scale well to ultra-large scale, heterogeneous code bases that contain millions of code files written in multiple programming languages. This paper presents Scaffle, the first scalable bug localization technique, which is based on the key insight to divide the problem into two easier sub-problems. First, a trained machine learning model predicts which lines of a raw crash trace are most informative for localizing the bug. Then, these lines are fed to an information retrieval-based search engine to retrieve file paths in the code base, predicting which file to change to address the crash. The approach does not make any assumptions about the format of a crash trace or the language that produces it. We evaluate Scaffle with tens of thousands of crash traces produced by a large-scale industrial code base at Facebook that contains millions of possible bug locations and that powers tools used by billions of people. The results show that the approach correctly predicts the file to fix for 40% to 60% (50% to 70%) of all crash traces within the top-1 (top-5) predictions. Moreover, Scaffle improves over several baseline approaches, including an existing classification-based approach, a scalable variant of existing information retrieval-based approaches, and a set of hand-tuned, industrially deployed heuristics.", "datasets": ""}, {"title": "A Commit Messages-Based Bug Localization for Android Applications", "authors": "Zhang Tao, Hu Wenjun, Luo Xiapu, Ma Xiaobo", "year": 2019, "classification": "IR-based bug localization", "tags": ["android"], "links": "https://doi.org/10.1142/S0218194019500207", "CCF": "C\u7c7b\u671f\u520a", "conference": "IJSEKE", "abstract": "Recently, there has been consistent growth in Android applications (apps). Under these circumstances, software maintenance for Android apps becomes an essential and important task. The core of software maintenance is to locate bugs in source files. Previous bug localization approaches mainly focus on open-source desktop software (e.g. Eclipse, Mozilla, GCC). Even though a few studies locate the bugs in the Android apps, they are dedicated to a special app named ZXing, without developing a general method to locate the bugs in Android apps by taking into account the unique characteristics of Android apps' bug reports. Such characteristics include fewer number of historical bug reports, insufficient detailed description, etc. These characteristics hinder existing localization approaches from being directly delivered to Android apps, because lack of enough information degrades the performance of those localization approaches relying on historical bug reports. Commit messages include more informative data which can provide the details of reported bugs. Therefore, in this paper, we propose a novel information retrieval-based approach which utilizes commit messages to locate new bugs in Android apps. This approach not only considers the structured textual similarity between the given bug and the candidate source files, but also computes the unstructured textual similarities between the new bug and the commit messages linked to the corresponding source files. According to the experimental results on 10 popular open-source Android apps managed by GitHub, our approach outperforms the state-of-the-art bug localization methods that include BugLocator, BLUiR, and two-phase model.", "datasets": ""}, {"title": "A Comparative Study of Vectorization Methods on BugLocator", "authors": "Amasaki Sousuke, Aman Hirohisa, Yokogawa Tomoyuki", "year": 2019, "classification": "Empirical study", "tags": ["empirical study"], "links": "https://doi.org/10.1109/SEAA.2019.00045", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "CONTEXT: Debugging is a labor-intensive and time-consuming activity. Automatic bug localization techniques have been proposed for reducing this effort. Among the techniques, Information retrieval (IR) based bug localization techniques take a bug report and give a rank list of source modules which are likely to cause the bug. Those techniques use a few variants of tf-idf vectorizations for bug reports and software modules though different vectorizations may give vastly different performances. OBJECTIVE: To explore the effects of vectorization methods on IR-based bug localization. METHOD: An empirical evaluation was conducted with 46 public data sets and 6 vectorization methods. BugLocator was used as a test bed. RESULTS: We found a vectorization used in BugLocator was one of the best. However, we found a better vectorization for representing software modules. CONCLUSIONS: It is worth to examine different vectorization methods for better IR-based bug localization because a preference for the methods can change as demonstrated in this study.", "datasets": ""}, {"title": "A novel approach to automatic query reformulation for IR-based bug localization", "authors": "Kim Misoo, Lee Eunseok", "year": 2019, "classification": "Query reformulation", "tags": ["query reformulation"], "links": "https://doi.org/10.1145/3297280.3297451", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Automatic query reformulation techniques for Information Retrieval based Bug Localization (IRBL) have been proposed to improve the quality of queries and IRBL performance. Recently proposed techniques determine the quality of queries via the bugs' description and reformulate them using important terms in the top-N source files retrieved by the initial query. However, the bugs' description may not contain enough information about the bugs, and the retrieved top-N files may not always provide important terms. In this paper, we propose a novel automatic query reformulation approach to improve IRBL performance beyond that of a recent technique. Our method expands bug reports using attachments and expands queries by reducing the noisy terms in them. We experimented with 1,546 bug reports. According to our results, we found that the quality of 70 reports was wrongly determined, and our method improved IRBL performance by up to 118% for these reports. Moreover, compared with a state-of-the-art technique, our method resulted in improvements of approximately 17% in Top-1, 11% in MRR@10, and 10% in MAP@10.", "datasets": ""}, {"title": "A Two-Phase Bug Localization Approach Based on Multi-layer Perceptrons and Distributional Features", "authors": "Liang Hongliang, Sun Lu, Wang Meilin, Yang Yuxing", "year": 2019, "classification": "Learning-based bug localization", "tags": ["word embedding", "deep learning", "dataset"], "links": "https://doi.org/10.1109/access.2019.2936948", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Bug localization is a challenging and time-consuming task of the process of bug fixing and, more in general, of software maintenance. Several approaches have been proposed in the literature which support developers in this task by identifying source code files in which the bug is likely to be located. However, the research on this topic never stopped, looking for new methods providing better accuracy and/or better efficiency. In this paper, we propose a two-phase bug localization approach which leverages multi-layer neural networks and distributional features. First phase locations are obtained thanks to a neural network trained on word embeddings representations of fixed bug reports. The second phase refines bug locations taking into account the number of times source code files co-occur in fixed bug locations. To evaluate the approach, we conducted a large-scale experiment on five open source projects, namely Mozilla, Eclipse, Dolphin, httpd, and gcc. Results show that, thanks to pre-trained word embeddings, we were able to implement a scalable approach with a training running time of few hours on large datasets. Performances are comparable to other existing deep learning approaches.", "datasets": "https://sites.google.com/unitelmasapienza.it/buglocalization"}, {"title": "Bug Localization for Version Issues With Defect Patterns", "authors": "Sun Xiaobing, Zhou Wei, Li Bin, Ni Zhen, Lu Jinting", "year": 2019, "classification": "IR-based bug localization", "tags": ["defect pattern"], "links": "https://doi.org/10.1109/ACCESS.2019.2894976", "CCF": "\u672a\u77e5", "conference": "Access", "abstract": "Version issues are becoming more and more prominent with the continuous development of software. Bug localization for version issues is time-consuming and labor-intensive. Although some bug localization techniques, such as those based on information retrieval (IR), have been proposed, they cannot handle these bugs very well as the version-related bugs have their own defect patterns. However, few existing works have focused on revealing these defect patterns and utilizing them for localization of bugs. To fill this gap, we propose a new approach by leveraging the version-related defect patterns to localize the version-related issues integrated with the IR technique. First, we extract version-related bugs from bug repositories and build a version-related bug repository. Given a new version-related bug report, we identify the defect patterns of corresponding similar historical bug reports from the version-related bug repository. Then, we combine these defect patterns with the IR technique to rank the candidate code snippets as suspicious code for developers to fix. The evaluation demonstrates that our approach is more effective to identify the faulty code related to version issues than the existing IR-based bug localization technique.", "datasets": ""}, {"title": "Bug Report Classification Using LSTM Architecture for More Accurate Software Defect Locating", "authors": "Ye Xin, Fang Fan, Wu John, Bunescu Razvan, Liu Chang", "year": 2019, "classification": "Learning-based bug localization", "tags": ["classification", "LSTM"], "links": "https://doi.org/10.1109/ICMLA.2018.00234", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Recently many information retrieval (IR)-based approaches have been proposed to help locate software defects automatically by using information from bug report contents. However, some bug reports that do not semantically related to the relevant code are not helpful to IR-based systems. Running an IR-based system on these reports may produce false positives. In this paper, we propose a classification model for classifying a bug report as either helpful or unhelpful using a LSTM-network. By filtering our unhelpful reports before running an IR-based bug locating system, our approach helps reduce false positives and improve the ranking performance. We test our model over 9,000 bug reports from three software projects. The evaluation result shows that our model helps improve a state-of-the-art IR-based system's ranking performance under a trade-off between the precision and the recall. Our comparison experiments show that the LSTM-network achieves the best trade-off between precision and recall than other classification models including CNN, multilayer perceptron, and a simple baseline approach that classifies a bug report based its length. In the situation that precision is more important than recall, our classification model helps for bug locating.", "datasets": ""}, {"title": "BULNER: BUg Localization with word embeddings and NEtwork Regularization", "authors": "Rodrigues Barbosa Jacson, Marcondes Marcacini Ricardo, Britto Ricardo, Soares Frederico, Rezende Solange, M. R. Vincenzi Auri, E. Delamaro M\u00e1rcio", "year": 2019, "classification": "Learning-based bug localization", "tags": ["word embedding"], "links": "https://doi.org/10.5753/vem.2019.7580", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Bug localization (BL) from the bug report is the strategic activity of the software maintaining process. Because BL is a costly and tedious activity, BL techniques information retrieval-based and machine learning-based could aid software engineers. We propose a method for BUg Localization with word embeddings and Network Regularization (BULNER). The preliminary results suggest that BULNER has better performance than two state-of-the-art methods.", "datasets": ""}, {"title": "D&C: A Divide-and-Conquer Approach to IR-based Bug Localization", "authors": "Koyuncu Anil, Bissyand\u00e9 Tegawend\u00e9 F., Kim Dongsun, Liu Kui, Klein Jacques, Monperrus Martin, Traon Yves Le", "year": 2019, "classification": "IR-based bug localization", "tags": ["classification"], "links": "http://arxiv.org/abs/1902.02703", "CCF": "A\u7c7b\u671f\u520a", "conference": "TSE", "abstract": "Many automated tasks in software maintenance rely on information retrieval techniques to identify specific information within unstructured data. Bug localization is such a typical task, where text in a bug report is analyzed to identify file locations in the source code that can be associated to the reported bug. Despite the promising results, the performance offered by IR-based bug localization tools is still not significant for large adoption. We argue that one reason could be the attempt to build a one-size-fits-all approach. In this paper, we extensively study the performance of state-of-the-art bug localization tools, focusing on query formulation and its importance with respect to the localization performance. Building on insights from this study, we propose a new learning approach where multiple classifier models are trained on clear-cut sets of bug-location pairs. Concretely, we apply a gradient boosting supervised learning approach to various sets of bug reports whose localizations appear to be successful with specific types of features. The training scenario builds on our findings that the various state-of-the-art localization tools can be highly performant for specific sets of bug reports. We implement D&C, which computes appropriate weights that should be assigned to the similarity measurements between pairs of information token types. Experimental results on large and up-to-date datasets reveal that D&C outperforms state-of-the-art tools. On average, the experiments yield an MAP score of 0.52, and an MRR score of 0.63 with a curated dataset, which provides a substantial performance improvement over all tools: MAP is improved by between 4 and up to 10 percentage points, while MRR is improved by between 1 and up to 12. Finally, we note that D&C is stable in its localization performance: around 50% of bugs can be located at Top1, 77% at Top5 and 85% at Top10.", "datasets": ""}, {"title": "Deep Learning for Bug-Localization in Student Programs", "authors": "Gupta Rahul, Kanade Aditya, Shevade Shirish", "year": 2019, "classification": "Learning-based bug localization", "tags": ["CNN"], "links": "http://arxiv.org/abs/1905.12454", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Providing feedback is an integral part of teaching. Most open online courses on programming make use of automated grading systems to support programming assignments and give real-time feedback. These systems usually rely on test results to quantify the programs' functional correctness. They return failing tests to the students as feedback. However, students may find it difficult to debug their programs if they receive no hints about where the bug is and how to fix it. In this work, we present the first deep learning based technique that can localize bugs in a faulty program w.r.t. a failing test, without even running the program. At the heart of our technique is a novel tree convolutional neural network which is trained to predict whether a program passes or fails a given test. To localize the bugs, we analyze the trained network using a state-of-the-art neural prediction attribution technique and see which lines of the programs make it predict the test outcomes. Our experiments show that the proposed technique is generally more accurate than two state-of-the-art program-spectrum based and one syntactic difference based bug-localization baselines.", "datasets": ""}, {"title": "Deep Learning With Customized Abstract Syntax Tree for Bug Localization", "authors": "Liang Hongliang, Sun Lu, Wang Meilin, Yang Yuxing", "year": 2019, "classification": "Learning-based bug localization", "tags": ["CNN", "deep learning"], "links": "https://doi.org/10.1109/access.2019.2936948", "CCF": "\u672a\u77e5", "conference": "Access", "abstract": "Given a bug report, bug localization technique can help developers automatically locate poten- tial buggy files. Information retrieval and deep learning approaches have been applied in bug localization by extracting lexical features in bug reports and syntactic features in source code files, though they fail to utilize the structural and semantic information of source code files. In this paper, we present a bug localization system CAST, which exploits deep learning and customized abstract syntax trees of programs to locate potential buggy source files automatically and effectively. Specifically, CAST extracts both lexical semantics in bug reports (e.g., words) and source files (e.g., method names) and program semantics in source files (e.g., abstract syntax tree, AST). Moreover, CAST enhances the tree-based convolutional neural network (TBCNN) model with customized ASTs, which distinguish between user-defined methods and system-provided ones to reflect their contributions leading to defects. Furthermore, customized ASTs group the syntactic entities with similar semantics and prune the ones with little or redundant semantics in order to facilitate the learning performance. Experimental results on four widely-used software projects show that CAST significantly outperforms the state-of-the-art methods in locating the buggy source files.", "datasets": ""}, {"title": "Deep Transfer Bug Localization", "authors": "Huo Xuan, Thung Ferdian, Li Ming, Lo David, Shi Shu-Ting", "year": 2019, "classification": "Learning-based bug localization", "tags": ["CNN", "cross-project"], "links": "https://doi.org/10.1109/tse.2019.2920771", "CCF": "A\u7c7b\u671f\u520a", "conference": "TSE", "abstract": "Many projects often receive more bug reports than what they can handle. To help debug and close bug reports, a number of bug localization techniques have been proposed. These techniques analyze a bug report and return a ranked list of potentially buggy source code files. Recent development on bug localization has resulted in the construction of effective supervised approaches that use historical data of manually localized bugs to boost performance. Unfortunately, as highlighted by Zimmermann et al., sufficient bug data is often unavailable for many projects and companies. This raises the need for cross-project bug localization \u2013 the use of data from a project to help locate bugs in another project. To fill this need, we propose a deep transfer learning approach for cross-project bug localization. Our proposed approach named TRANP-CNN extracts transferable semantic features from source project and fully exploits labeled data from target project for effective cross-project bug localization. We have evaluated TRANP-CNN on curated high-quality bug datasets and our experimental results show that TRANP-CNN can locate buggy files correctly at top 1, top 5, and top 10 positions for 29.9%, 51.7%, 61.3% of the bugs respectively, which significantly outperform state-of-the-art bug localization solution based on deep", "datasets": ""}, {"title": "FineLocator: A novel approach to method-level fine-grained bug localization by query expansion", "authors": "Zhang Wen, Li Ziqiang, Wang Qing, Li Juan", "year": 2019, "classification": "Learning-based bug localization", "tags": ["method level", "word embedding", "call dependency", "version history"], "links": "https://doi.org/10.1016/j.infsof.2019.03.001", "CCF": "B\u7c7b\u671f\u520a", "conference": "IST", "abstract": "Context: Bug localization, namely, to locate suspicious snippets from source code files for developers to fix the bug, is crucial for software quality assurance and software maintenance. Effective bug localization technique is desirable for software developers to reduce the effort involved in bug resolution. State-of-the-art bug localization techniques concentrate on file-level coarse-grained localization by lexical matching bug reports and source code files. However, this would bring about a heavy burden for developers to locate feasible code snippets to make change with the goal of fixing the bug. Objective: This paper proposes a novel approach called FineLocator to method-level fine-grained bug localization by using semantic similarity, temporal proximity and call dependency for method expansion. Method: Firstly, the bug reports and the methods of source code are represented by numeric vectors using word embedding (word2vec) and the TF-IDF method. Secondly, we propose three query expansion scores as semantic similarity score, temporal proximity score and call dependency score to address the representation sparseness problem caused by the short lengths of methods in the source code. Then, the representation of a method with short length is augmented by elements of its neighboring methods with query expansion. Thirdly, when a new bug report is incoming, FineLocator will retrieve the methods in source code by similarity ranking on the bug report and the augmented methods for bug localization. Results: We collect bug repositories of ArgoUML, Maven, Kylin, Ant and AspectJ projects to investigate the performance of the proposed FineLocator approach. Experimental results demonstrate that the proposed FineLocator approach can improve the performances of method-level bug localization at average by 20%, 21% and 17% measured by Top-N indicator, MAP and MRR respectively, in comparison with state-of-the-art techniques. Conclusion: This is the first paper to demonstrate how to make use of method expansion to address the representation sparseness problem for method-level fine-grained bug localization.", "datasets": ""}, {"title": "Improving bug localization with word embedding and enhanced convolutional neural networks", "authors": "Xiao Yan, Keung Jacky, Bennin Kwabena E., Mi Qing", "year": 2019, "classification": "Learning-based bug localization", "tags": ["word embedding", "CNN"], "links": "https://doi.org/10.1016/j.infsof.2018.08.002", "CCF": "B\u7c7b\u671f\u520a", "conference": "IST", "abstract": "Context: Automatic localization of buggy files can speed up the process of bug fixing to improve the efficiency and productivity of software quality assurance teams. Useful semantic information is available in bug reports and source code, but it is usually underutilized by existing bug localization approaches. Objective: To improve the performance of bug localization, we propose DeepLoc, a novel deep learning-based model that makes full use of semantic information. Method: DeepLoc is composed of an enhanced convolutional neural network (CNN) that considers bug-fixing recency and frequency, together with word-embedding and feature-detecting techniques. DeepLoc uses word embeddings to represent the words in bug reports and source files that retain their semantic information, and different CNNs to detect features from them. DeepLoc is evaluated on over 18,500 bug reports extracted from AspectJ, Eclipse, JDT, SWT, and Tomcat projects. Results: The experimental results show that DeepLoc achieves 10.87%\u201313.4% higher MAP (mean average precision) than conventional CNN. DeepLoc outperforms four current state-of-the-art approaches (DeepLocator, HyLoc, LR+WE, and BugLocator) in terms of Accuracy@k (the percentage of bug reports for which at least one real buggy file is located within the top k rank), MAP, and MRR (mean reciprocal rank) using less computation time. Conclusion: DeepLoc is capable of automatically connecting bug reports to the corresponding buggy files and achieves better performance than four state-of-the-art approaches based on a deep understanding of semantics in bug reports and source code.", "datasets": ""}, {"title": "Mapping Bug Reports to Relevant Source Code Files Based on the Vector Space Model and Word Embedding", "authors": "Liu Guangliang, Lu Yang, Shi Ke, Chang Jingfei, Wei Xing", "year": 2019, "classification": "Learning-based bug localization", "tags": ["VSM", "word embedding"], "links": "https://doi.org/10.1109/ACCESS.2019.2922686", "CCF": "\u672a\u77e5", "conference": "Access", "abstract": "Although software bug localization in software maintenance and evolution is cumbersome and time-consuming, it is also very important, especially for large-scale software projects. To lighten the workload of developers, researchers have developed various information retrieval (IR)-based bug localization models for automated software support. In this paper, we propose a new method that reduces the time required for bug localization. First, the surface lexical similarity between a bug report and source code file is calculated based on the vector space model. Second, to address the lexical gap between the programming language and natural language, the word vector is used to calculate the semantic similarity between the bug report and source code file. Then, we use surface lexical and semantic similarity to calculate the total similarity for detecting buggy source code files. Our experimental word vectors are derived from Skip-gram and GloVe model training. We select an optimal 100 dimensional word vector for bug localization by evaluating it on four open source software examples. Finally, our experimental results show that our method outperforms classical IR-based methods in locating relevant source code files based on several indicators.", "datasets": ""}, {"title": "Network-Clustered Multi-Modal Bug Localization", "authors": "Hoang Thong Van Duc, Oentaryo Richard J., Le Tien Duy Bui, Lo David", "year": 2019, "classification": "IR-based bug localization", "tags": ["program spectrum"], "links": "https://doi.org/10.1109/TSE.2018.2810892", "CCF": "A\u7c7b\u671f\u520a", "conference": "TSE", "abstract": "Developers often spend much effort and resources to debug a program. To help the developers debug, numerous information retrieval (IR)-based and spectrum-based bug localization techniques have been devised. IR-based techniques process textual information in bug reports, while spectrum-based techniques process program spectra. While both techniques ultimately generate a ranked list of program elements that likely contain a bug, they only consider one source of information&#x2014;either bug reports or program spectra&#x2014;which is not optimal. In light of this deficiency, this paper presents a new approach dubbed Network-clustered Multi-modal Bug Localization (NetML), which utilizes multi-modal information from both bug reports and program spectra to localize bugs. NetML facilitates an effective bug localization by carrying out a joint optimization of bug localization error and clustering of both bug reports and program elements. Extensive experiments on 355 real bugs from seven software systems have been conducted to evaluate NetML against various state-of-the-art localization methods. The results show that NetML surpasses the best-performing baseline by 31.82%, 22.35%, 19.72%, and 19.24%, in terms of the number of bugs successfully localized when a developer inspects the top 1, 5, and 10 methods and Mean Average Precision (MAP), respectively.", "datasets": ""}, {"title": "On Usefulness of the Deep-Learning-Based Bug Localization Models to Practitioners", "authors": "Polisetty Sravya, Miranskyy Andriy, Bener Ayse ", "year": 2019, "classification": "Empirical study", "tags": ["empirical study"], "links": "https://doi.org/10.1145/3345629.3345632", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Background: Developers spend a significant amount of time and efforts to localize bugs. In the literature, many researchers proposed state-of-the-art bug localization models to help developers localize bugs easily. The practitioners, on the other hand, expect a bug localization tool to meet certain criteria, such as trustworthiness, scalability, and efficiency. The current models are not capable of meeting these criteria, making it harder to adopt these models in practice. Recently, deep-learning-based bug localization models have been proposed in the literature, which show a better performance than the state-of-the-art models. Aim: In this research, we would like to investigate whether deep learning models meet the expectations of practitioners or not. Method: We constructed a Convolution Neural Network and a Simple Logistic model to examine their effectiveness in localizing bugs. We train these models on five open source projects written in Java and compare their performance with the performance of other state-of-the-art models trained on these datasets. Results: Our experiments show that although the deep learning models perform better than classic machine learning models, they meet the adoption criteria set by the practitioners only partially. Conclusions: This work provides evidence that the practitioners should be cautious while using the current state of the art models for production-level use-cases. It also highlights the need for standardization of performance benchmarks to ensure that bug localization models are assessed equitably and realistically.", "datasets": ""}, {"title": "Review of Text Mining Techniques for Software Bug Localization", "authors": "Tamanna, Sangwan Om Prakash", "year": 2019, "classification": "IR-based bug localization", "tags": ["empirical study"], "links": "https://doi.org/10.1109/CONFLUENCE.2019.8776959", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Software Bug Localization (SBL) is a task of locating the buggy source code. There are various ways of doing SBL and one of them is static SBL which utilizes the power of Text Mining (TM) in association with software repositories. Most of static SBL models are based on Information Retrieval (IR) methodology in which bug report works as a query and source code as database. In this paper we review state of the art SBL models which uses text mining techniques as their back bone in conjunction with other techniques. Essential features are extracted and summarized with the help of tabular representation. Aim of doing this study is to find the gaps in previous SBL models for proposing a novel SBL model in future.", "datasets": ""}, {"title": "SCOR--Source Code Retrieval With Semantics and Order", "authors": "Akbar Shayan A., Kak Avinash C.", "year": 2019, "classification": "Learning-based bug localization", "tags": ["word embedding"], "links": "https://doi.org/10.1109/MSR.2019.00012", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "MSR", "abstract": "Word embeddings produced by the word2vec algorithm provide us with a strong mechanism to discover relationships between the words based on the degree to which they are contextually related to one another. In and of itself, algorithms like word2vec do not give us a mechanism to impose ordering constraints on the embedded word representations. Our main goal in this paper is to exploit the semantic word vectors obtained from word2vec in such a way that allows for the ordering constraints to be invoked on them when comparing a sequence of words in a query with a sequence of words in a file for source code retrieval. These ordering constraints employ the logic of Markov Random Fields (MRF), a framework used previously to enhance the precision of the source-code retrieval engines based on the Bag-of-Words (BoW) assumption. The work we present here demonstrates that by combining word2vec with the power of MRF, it is possible to achieve improvements between 6% and 30% in retrieval accuracy over the best results that can be obtained with the more traditional applications of MRF to representations based on term and term-term frequencies. The performance improvement was 30% for the Java AspectJ repository using only the titles of the bug reports provided by iBUGS, and 6% for the case of the Eclipse repository using titles as well as descriptions of the bug reports provided by BUGLinks.", "datasets": ""}, {"title": "Source Code Retrieval for Bug Localization using Bug Report", "authors": "Swe Kyaw Ei Ei, Oo Hnin Min", "year": 2019, "classification": "IR-based bug localization", "tags": ["version history", "structure"], "links": "https://doi.org/10.1109/ICCP48234.2019.8959535", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICPC", "abstract": "Bug localization helps software developers to track post-released faulty source files with the help of user's reported bug files. Information retrieval (IR) based bug localization have been widely used in recent years. It recommends relevant faulty source files to fix according to their highest similarity scores. We propose a combined approach of IR-based bug localization by operating previously fixed bug reports and source code structure. From the query, bug report structure is also considered to get more accurate faulty source files. In our approach, three parts in the source code file and two parts in bug report are combined as six combinations score. In some bug localization approach, features are usually linearly combined. Our approach uses linearly combine with the weight value. We perform experiments on three projects, i.e. SWT, AspectJ, and Eclipse. The result shows that the proposed approach achieves the relevance accuracy for bug localization process. According to the evaluation result, using the structure is more localized than no structured approach.", "datasets": ""}, {"title": "Structured information in bug report descriptions\u2014influence on IR-based bug localization and developers", "authors": "Rath Michael, M\u00e4der Patrick", "year": 2019, "classification": "Empirical study", "tags": ["version history", "structure"], "links": "https://doi.org/10.1007/s11219-019-09445-6", "CCF": "C\u7c7b\u671f\u520a", "conference": "SQJ", "abstract": "Multiple information retrieval (IR)-based bug localization techniques have been proposed over the last years. The foundation of the approaches relies on textual similarity of the bug report description and the source code files. The basic assumption is that these descriptions are well suited to query the code base. However, often bug reports contain structured information such as stack traces and source code next to natural language, which might interfere with the initial belief. In this paper, we systematically analyze the influence of structured information on IR-based techniques. Therefore, an empirical study on 7334 bug reports, out of which more than 30% contain structured information, was carried out. Based on the results, a follow-up user study was conducted focusing on source code fragments found in bug reports. Our results show that stack traces tend to negatively affect IR-based bug localization performance and require special handling. Compared to natural language\u2013only reports, source code is beneficial for IR-based algorithms, as well as for developers to identify false positives in bug localization results.", "datasets": ""}, {"title": "Supporting Code Search with Context-Aware, Analytics-Driven, Effective Query Reformulation", "authors": "Rahman Mohammad Masudur", "year": 2019, "classification": "Query reformulation", "tags": ["query reformulation"], "links": "https://doi.org/10.1109/ICSE-Companion.2019.00088", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ICSE", "abstract": "Software developers often experience difficulties in preparing appropriate queries for code search. Recent finding has suggested that developers fail to choose the right search keywords from an issue report for 88% of times. Thus, despite a number of earlier studies, automatic reformulation of queries for the code search is an open problem which warrants further investigations. In this dissertation work, we hypothesize that code search could be improved by adopting appropriate term weighting, context-awareness and data-analytics in query reformulation. We ask three research questions to evaluate the hypothesis, and then conduct six studies to answer these questions. Our proposed approaches improve code search by incorporating (1) novel, appropriate keyword selection algorithms, (2) context-awareness, (3) crowdsourced knowledge from Stack Overflow, and (4) large-scale data analytics into the query reformulation process.", "datasets": ""}, {"title": "Toward Optimal Selection of Information Retrieval Models for Software Engineering Tasks", "authors": "Rahman Masudur, Chakraborty Saikat, Kaiser Gail, Ray Baishakhi", "year": 2019, "classification": "Empirical study", "tags": ["dataset"], "links": "https://doi.org/10.1109/SCAM.2019.00022", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "SCAM", "abstract": "Information Retrieval (IR) plays a pivotal role in diverse Software Engineering (SE) tasks, e.g., bug localization and triaging, bug report routing, code retrieval, requirements analysis, etc. SE tasks operate on diverse types of documents including code, text, stack-traces, and structured, semi-structured and unstructured meta-data that often contain specialized vo- cabularies. As the performance of any IR-based tool critically depends on the underlying document types, and given the diversity of SE corpora, it is essential to understand which models work best for which types of SE documents and tasks. We empirically investigate the interaction between IR models and document types for two representative SE tasks (bug lo- calization and relevant project search), carefully chosen as they require a diverse set of SE artifacts (mixtures of code and text), and confirm that the models\u2019 performance varies significantly with mix of document types. Leveraging this insight, we propose a generalized framework, SRCH, to automatically select the most favorable IR model(s) for a given SE task. We evaluate SRCH w.r.t. these two tasks and confirm its effectiveness. Our preliminary user study shows that SRCH\u2019s intelligent adaption of the IR model(s) to the task at hand not only improves precision and recall for SE tasks but may also improve users\u2019 satisfaction.", "datasets": "https://github.com/masud99r/IR-in-SE"}, {"title": "Using bug descriptions to reformulate queries during text-retrieval-based bug localization", "authors": "Chaparro Oscar, Florez Juan Manuel, Marcus Andrian", "year": 2019, "classification": "Query reformulation", "tags": ["query reformulation"], "links": "https://doi.org/10.1007/s10664-018-9672-z", "CCF": "\u672a\u77e5", "conference": "EMSE", "abstract": "Text Retrieval (TR)-based approaches for bug localization rely on formulating an initial query based on the full text of a bug report. When the query fails to retrieve the buggy code artifacts, developers can reformulate the query and retrieve more candidate code documents. Existing research on query reformulation focuses mostly on leveraging relevance feedback from the user or on expanding the original query with additional information. We hypothesize that the title of the bug reports, the observed behavior, expected behavior, steps to reproduce, and code snippets provided by the users in bug descriptions, contain the most relevant information for retrieving the buggy code artifacts, and that other parts of the descriptions contain more irrelevant terms, which hinder retrieval. This paper proposes and evaluates a set of query reformulation strategies based on the selection of existing information in bug descriptions, and the removal of irrelevant parts from the original query. The results show that selecting the bug report title and the observed behavior is the strategy that performs best across various TR-based bug localization approaches and code granularities, as it leads to retrieving the buggy code artifacts within the top-N results for 25.6% more queries (on average) than without query reformulation. This strategy is highly applicable and consistent across different thresholds N. Selecting the steps to reproduce or the expected behavior (when provided in the bug reports) along with the bug title and the observed behavior leads to higher performance (i.e., between 31.4% and 41.7% more queries) and comparable consistency, yet it is applicable in fewer cases. These reformulation strategies are easy to use and are independent of the underlying retrieval technique.", "datasets": ""}, {"title": "A preliminary study on using code smells to improve bug localization", "authors": "Takahashi Aoi, Sae-Lim Natthawute, Hayashi Shinpei, Saeki Motoshi", "year": 2018, "classification": "IR-based bug localization", "tags": ["code smell"], "links": "https://doi.org/10.1145/3196321.3196361", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ICSE", "abstract": "Bug localization is a technique that has been proposed to support the process of identifying the locations of bugs specified in a bug report. A traditional approach such as information retrieval (IR)-based bug localization calculates the similarity between the bug description and the source code and suggests locations that are likely to contain the bug. However, while many approaches have been proposed to improve the accuracy, the likelihood of each module having a bug is often overlooked or they are treated equally, whereas this may not be the case. For example, modules having code smells have been found to be more prone to changes and faults. Therefore, in this paper, we explore a first step toward leveraging code smells to improve bug localization. By combining the code smell severity with the textual similarity from IR-based bug localization, we can identify the modules that are not only similar to the bug description but also have a higher likelihood of containing bugs. Our preliminary evaluation on four open source projects shows that our technique can improve the baseline approach by 142.25% and 30.50% on average for method and class levels, respectively.", "datasets": ""}, {"title": "Analyzing requirements and traceability information to improve bug localization", "authors": "Rath Michael, Lo David, M\u00e4der Patrick", "year": 2018, "classification": "IR-based bug localization", "tags": ["stack trace"], "links": "https://doi.org/10.1145/3196398.3196415", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "MSR", "abstract": "Locating bugs in industry-size software systems is time consuming and challenging. An automated approach for assisting the process of tracing from bug descriptions to relevant source code benefits developers. A large body of previous work aims to address this problem and demonstrates considerable achievements. Most existing approaches focus on the key challenge of improving techniques based on textual similarity to identify relevant files. However, there exists a lexical gap between the natural language used to formulate bug reports and the formal source code and its comments. To bridge this gap, state-of-the-art approaches contain a component for analyzing bug history information to increase retrieval performance. In this paper, we propose a novel approach TraceScore that also utilizes projects' requirements information and explicit dependency trace links to further close the gap in order to relate a new bug report to defective source code files. Our evaluation on more than 13,000 bug reports shows, that TraceScore significantly outperforms two state-of-the-art methods. Further, by integrating TraceScore into an existing bug localization algorithm, we found that TraceScore significantly improves retrieval performance by 49% in terms of mean average precision (MAP).", "datasets": ""}, {"title": "Are Bug Reports Enough for Text Retrieval-Based Bug Localization?", "authors": "Mills Chris, Pantiuchina Jevgenija, Parra Esteban, Bavota Gabriele, Haiduc Sonia", "year": 2018, "classification": "Empirical study", "tags": ["empirical study"], "links": "https://doi.org/10.1109/ICSME.2018.00046", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICSME", "abstract": "Text Retrieval (TR) has been widely used to support many software engineering tasks, including bug localization (i.e., the activity of localizing buggy code starting from a bug report). Many studies show TR's effectiveness in lowering the manual effort required to perform this maintenance task; however, the actual usefulness of TR-based bug localization has been questioned in recent studies. These studies discuss (i) potential biases in the experimental design usually adopted to evaluate TRbased bug localization techniques and (ii) their poor performance in the scenario when they are needed most: when the bug report, which serves as the de facto query in most studies, does not contain localization hints (e.g., code snippets, method names, etc.) Fundamentally, these studies raise the question: do bug reports provide sufficient information to perform TR-based localization? In this work, we approach that question from two perspectives. First, we investigate potential biases in the evaluation of TR-based approaches which artificially boost the performance of these techniques, making them appear more successful than they are. Second, we analyze bug report text with and without localization hints using a genetic algorithm to derive a near-optimal query that provides insight into the potential of that bug report for use in TR-based localization. Through this analysis we show that in most cases the bug report vocabulary (i.e., the terms contained in the bug title and description) is all we need to formulate effective queries, making TR-based bug localization successful without supplementary query expansion. Most notably, this also holds when localization hints are completely absent from the bug report. In fact, our results suggest that the next major step in improving TR-based bug localization is the ability to formulate these near-optimal queries.", "datasets": ""}, {"title": "Are information retrieval-based bug localization techniques trustworthy?", "authors": "Kim Misoo, Lee Eunseok", "year": 2018, "classification": "Empirical study", "tags": ["empirical study"], "links": "https://doi.org/10.1145/3183440.3194954", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ICSE", "abstract": "Information retrieval-based bug localization techniques are evaluated using datasets with an oracle. However, datasets can contain non-buggy files, which affect the reliability of these techniques. To investigate the impact of non-buggy files, we show that a test file can be regarded as a buggy file. Then, we determined if this file caused inaccuracies that would eventually affect the trustworthiness of previous techniques. We further analyzed the impact of test files on IR-based bug localization through three research questions. Our results show that the test files significantly impact the performance of the techniques. Furthermore, MAP increased by a maximum of 21%, and MRR decreased by a maximum of 13%.", "datasets": ""}, {"title": "Bench4BL: reproducibility study on the performance of IR-based bug localization", "authors": "Lee Jaekwon, Kim Dongsun, Bissyand\u00e9 Tegawend\u00e9 F., Jung Woosung, Le Traon Yves", "year": 2018, "classification": "Datasets", "tags": ["dataset"], "links": "https://doi.org/10.1145/3213846.3213856", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ISSTA", "abstract": "In recent years, the use of Information Retrieval (IR) techniques to automate the localization of buggy files, given a bug report, has shown promising results. The abundance of approaches in the literature, however, contrasts with the reality of IR-based bug localization (IRBL) adoption by developers (or even by the research community to complement other research approaches). Presumably, this situation is due to the lack of comprehensive evaluations for state-of-the-art approaches which offer insights into the actual performance of the techniques. We report on a comprehensive reproduction study of six stateof-the-art IRBL techniques. This study applies not only subjects used in existing studies (old subjects) but also 46 new subjects (61,431 Java files and 9,459 bug reports) to the IRBL techniques. In addition, the study compares two different version matching (between bug reports and source code files) strategies to highlight our observations related to performance deterioration.We also vary test file inclusion to investigate the effectiveness of IRBL techniques on test files, or its noise impact on performance. Finally, we assess potential performance gain if duplicate bug reports are leveraged.", "datasets": "https://github.com/exatoa/Bench4BL"}, {"title": "Bug Localization Approach Using Source Code Structure with Different Structure Fields", "authors": "Swe Kyaw Ei Ei, Oo Hnin Min", "year": 2018, "classification": "IR-based bug localization", "tags": ["structure"], "links": "https://doi.org/10.1109/SERA.2018.8477206", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "In bug localization approach, the information of the bug was used by developer to modify the source code where the errors occurred. To fix the source code that need to be correct is a problem for developer. Numerous automatic bug localization approaches by using information retrieval have been proposed. In this paper, we propose bug localization approach by combining structure of source code with different structure fields, similarity of bugs and stack-trace. It recommends relevance bug files to fix according to their highest scores. We additionally propose bug localization to consider the source code with three difference structure fields. In recent approaches source code files are consider as a single units. It may cause many noises when the source code file is large. We implement our approach on four open source projects (AspectJ, Eclipse and SWT). We then compute our approach in term of top-N rank, mean average precision (MAP) and mean reciprocal rank (MRR) evaluation metrics. The results show that the proposed system achieves significant results.", "datasets": ""}, {"title": "Bug Localization by Learning to Rank and Represent Bug Inducing Changes", "authors": "Loyola Pablo, Gajananan Kugamoorthy, Satoh Fumiko", "year": 2018, "classification": "Learning-based bug localization", "tags": ["method level", "change history", "learn to rank"], "links": "https://doi.org/10.1145/3269206.3271811", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "CIKM", "abstract": "In software development, bug localization is the process finding portions of source code associated to a submitted bug report. This task has been modeled as an information retrieval task at source code file, where the report is the query. In this work, we propose a model that, instead of working at file level, learns feature representations from source changes extracted from the project history at both syntactic and code change dependency perspectives to support bug localization. To that end, we structured an end-to-end architecture able to integrate feature learning and ranking between sets of bug reports and source code changes. We evaluated our model against the state of the art of bug localization on several real world software projects obtaining competitive results in both intra-project and cross-project settings. Besides the positive results in terms of model accuracy, as we are giving the developer not only the location of the bug associated to the report, but also the change that introduced, we believe this could give a broader context for supporting fixing tasks.", "datasets": ""}, {"title": "Bug Localization via Supervised Topic Modeling", "authors": "Wang Yaojing, Yao Yuan, Tong Hanghang, Huo Xuan, Li Min, Xu Feng, Lu Jian", "year": 2018, "classification": "IR-based bug localization", "tags": ["topic model"], "links": "https://doi.org/10.1109/ICDM.2018.00076", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICDM", "abstract": "Bug tracking systems, which help to track the reported software bugs, have been widely used in software development and maintenance. In these systems, recognizing relevant source files among a large number of source files for a given bug report is a time-consuming and labor-intensive task for software developers. To tackle this problem, information retrieval methods have been widely used to capture either the textual similarities or the semantic similarities between bug reports and source files. However, these two types of similarities are usually considered separately and the historical bug fixings are largely ignored by the existing methods. In this paper, we propose a supervised topic modeling method (STMLOCATOR) for automatically locating the relevant source files for a given bug report. In particular, the proposed model is built upon three key observations. First, supervised modeling can effectively make use of the existing fixing histories. Second, certain words in bug reports tend to appear multiple times in their relevant source files. Third, longer source files tend to have more bugs. By integrating the above three observations, the proposed STMLOCATOR utilizes historical fixings in a supervised way and learns both the textual similarities and semantic similarities between bug reports and source files. We further consider a special type of bug reports with stack-traces in bug reports, and propose a variant of STMLOCATOR to tailor for such bug reports. Experimental evaluations on three real data sets demonstrate that the proposed STMLOCATOR can achieve up to 23.6% improvement in terms of prediction accuracy over its best competitors, and scales linearly with the size of the data. Moreover, the proposed variant further improves STMLOCATOR by up to 76.2% on those bug reports with stack-traces.", "datasets": ""}, {"title": "Bug localization with semantic and structural features using convolutional neural network and cascade forest", "authors": "Xiao Yan, Keung Jacky, Mi Qing, Bennin Kwabena E.", "year": 2018, "classification": "Learning-based bug localization", "tags": ["CNN", "deep learning"], "links": "https://doi.org/10.1145/3210459.3210469", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "EASE", "abstract": "Background: Correctly localizing buggy files for bug reports together with their semantic and structural information is a crucial task, which would essentially improve the accuracy of bug localization techniques. Aims: To empirically evaluate and demonstrate the effects of both semantic and structural information in bug reports and source files on improving the performance of bug localization, we propose CNN Forest involving convolutional neural network and ensemble of random forests that have excellent performance in the tasks of semantic parsing and structural information extraction. Method: We first employ convolutional neural network with multiple filters and an ensemble of random forests with multi-grained scanning to extract semantic and structural features from the word vectors derived from bug reports and source files. And a subsequent cascade forest (a cascade of ensembles of random forests) is used to further extract deeper features and observe the correlated relationships between bug reports and source files. CNN Forest is then empirically evaluated over 10,754 bug reports extracted from AspectJ, Eclipse UI, JDT, SWT, and Tomcat projects. Results: The experiments empirically demonstrate the significance of including semantic and structural information in bug localization, and further show that the proposed CNN Forest achieves higher Mean Average Precision and Mean Reciprocal Rank measures than the best results of the four current state-of-the-art approaches (NP-CNN, LR+WE, DNNLOC, and BugLocator). Conclusion: CNN Forest is capable of defining the correlated relationships between bug reports and source files, and we empirically show that semantic and structural information in bug reports and source files are crucial in improving bug localization.", "datasets": ""}, {"title": "Comparing learning to rank techniques in hybrid bug localization", "authors": "Shi Zhendong, Keung Jacky, Bennin Kwabena Ebo, Zhang Xingjun", "year": 2018, "classification": "Empirical study", "tags": ["learn to rank", "empirical study"], "links": "https://doi.org/10.1016/j.asoc.2017.10.048", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Bug localization is a software development and maintenance activity that aims to find relevant source code entities to be modified so that a specific bug can be fixed on the basis of the given bug report. Information retrieval (IR) techniques have been widely used to locate bugs in recent decades. These techniques mainly use the IR similarity between the bug report and source code entities. In addition to IR similarity, features that are extracted from version history, source code structure, dynamic analysis, and other resources are found to be beneficial for bug localization. The approaches utilizing extra features in IR-based bug localization are called hybrid bug localization. We conduct a short survey of the hybrid bug localization methods that use additional features in addition to IR similarity. We also use Learning to Rank (LtR) techniques to combine the beneficial features to improve bug localization. Learning to Rank is the application of machine learning in the ranking models for information retrieval. We compared eight LtR techniques in bug localization, and the experimental results show that coordinate ascent algorithms without normalization is a suitable LtR technique in bug localization for selected attributes, and it outperforms two state-of-the-art localization approaches for two large projects, Eclipse and SWT.", "datasets": ""}, {"title": "Fusing multi-abstraction vector space models for concern localization", "authors": "Zhang Yun, Lo David, Xia Xin, Scanniello Giuseppe, Le Tien Duy B., Sun Jianling", "year": 2018, "classification": "IR-based bug localization", "tags": ["VSM", "concern localization", "topic model"], "links": "https://doi.org/10.1007/s10664-017-9585-2", "CCF": "\u672a\u77e5", "conference": "EMSE", "abstract": "Concern localization refers to the process of locating code units that match a particular textual description. It takes as input textual documents such as bug reports and feature requests and outputs a list of candidate code units that are relevant to the bug reports or feature requests. Many information retrieval (IR) based concern localization techniques have been proposed in the literature. These techniques typically represent code units and textual descriptions as a bag of tokens at one level of abstraction, e.g., each token is a word, or each token is a topic. In this work, we propose a multi-abstraction concern localization technique named M ULAB. M ULAB represents a code unit and a textual description at multiple abstraction levels. Similarity of a textual description and a code unit is now made by considering all these abstraction levels. We combine a vector space model (VSM) and multiple topic models to compute the similarity and apply a genetic algorithm to infer semi-optimal topic model configurations. We also propose 12 variants of M ULAB by using different data fusion methods. We have evaluated our solution on 175 concerns from 9 open source Java software systems. The experimental results show that variant CombMNZ-Def performs better than other variants, and also outperforms the state-of-art baseline called P R (PageRank based algorithm), which is proposed by Scanniello et al. (Empir Softw Eng 20(6):1666\u20131720 2015) in terms of effectiveness and rank.", "datasets": ""}, {"title": "Improving Bug Localization with Character-Level Convolutional Neural Network and Recurrent Neural Network", "authors": "Xiao Yan, Keung Jacky", "year": 2018, "classification": "Learning-based bug localization", "tags": ["CNN", "deep learning", "RNN"], "links": "https://doi.org/10.1109/APSEC.2018.00097", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "APSEC", "abstract": "Automated bug localization in large amounts of source files for bug reports is a crucial task in software engineering. However, the different representations of bug reports and source files limited the accuracy of the existing bug localization techniques. Aims: We propose a novel deep learning-based model to improve the accuracy of bug localization for bug reports by expressing them in character and analyzing them with a language model. Method: The proposed model is composed of two main parts: character-level convolutional neural network (CNN) and recurrent neural network (RNN) language model. Both bug reports and source files are expressed in a character level and then input into a CNN, whose output is given to an RNN encoder-decoder architecture. Results: The results of preliminary experiments show that the proposed model achieves comparable or even higher accuracy than the existing machine translation-based bug localization technique. Conclusion: The proposed model is capable of automatically localizing buggy files for bug reports and achieves better accuracy by analyzing them in character level where both bug reports and source code can be expressed.", "datasets": ""}, {"title": "Improving IR-Based Bug Localization with Context-Aware Query Reformulation", "authors": "Rahman Mohammad Masudur, Roy Chanchal K.", "year": 2018, "classification": "Query reformulation", "tags": ["query reformulation"], "links": "https://doi.org/10.1145/3236024.3236065", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ESEC/FSE", "abstract": "Recent findings suggest that Information Retrieval (IR)-based bug localization techniques do not perform well if the bug report lacks rich structured information (e.g., relevant program entity names). Conversely, excessive structured information (e.g., stack traces) in the bug report might not always help the automated localization either. In this paper, we propose a novel techniqueSBLIZZARDS that automatically localizes buggy entities from project source using appropriate query reformulation and effective information retrieval. In particular, our technique determines whether there are excessive program entities or not in a bug report (query), and then applies appropriate reformulations to the query for bug localization. Experiments using 5,139 bug reports show that our technique can localize the buggy source documents with 7%S56% higher Hit@10, 6%S 62% higher MAP@10 and 6%S62% higher MRR@10 than the baseline technique. Comparison with the state-of-the-art techniques and their variants report that our technique can improve 19% in MAP@10 and 20% in MRR@10 over the state-of-the-art, and can improve 59% of the noisy queries and 39% of the poor queries.", "datasets": ""}, {"title": "Influence of Structured Information in Bug Report Descriptions on IR-Based Bug Localization", "authors": "Rath Michael, M\u00e4der Patrick", "year": 2018, "classification": "Empirical study", "tags": ["empirical study"], "links": "https://doi.org/10.1109/SEAA.2018.00014", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Over the years, researcher proposed multiple information retrieval (IR) based bug localization techniques. The foundation of the approaches relies on textual similarity of the bug report description and the source code files. The basic assumption is that these descriptions are well suited to query the code base. However, often bug reports contain structured information such as stack traces and source code next to natural language, which might interfere with the initial belief. In this paper, we systematically analyze the influence of structured information on IR-based techniques. Therefore a study on 7,334 bug reports, out of which more than 30% contain structured information, was conducted. Our results show, that stack traces tend to negatively affect IR-based bug localization performance and require special handling.", "datasets": ""}, {"title": "Just enough semantics : An information theoretic approach for IR-based software bug localization", "authors": "Khatiwada Saket, Tushev Miroslav, Mahmoud Anas", "year": 2018, "classification": "IR-based bug localization", "tags": ["information theory"], "links": "https://doi.org/10.1016/j.infsof.2017.08.012", "CCF": "B\u7c7b\u671f\u520a", "conference": "IST", "abstract": "Context Software systems are often shipped with defects. Whenever a bug is reported, developers use the information available in the associated report to locate source code fragments that need to be modified in order to fix the bug. However, as software systems evolve in size and complexity, bug localization can become a tedious and time-consuming process. To minimize the manual effort, contemporary bug localization tools utilize Information Retrieval (IR) methods for automated support. IR methods exploit the textual content of bug reports to automatically capture and rank relevant buggy source files. Objective In this paper, we propose a new paradigm of information-theoretic IR methods to support bug localization tasks in software systems. These methods, including Pointwise Mutual Information (PMI) and Normalized Google Distance (NGD), exploit the co-occurrence patterns of code terms in the software system to reveal hidden textual semantic dimensions that other methods often fail to capture. Our objective is establish accurate semantic similarity relations between source code and bug reports. Method Five benchmark datasets from different application domains are used to conduct our analysis. The proposed methods are compared against classical IR methods that are commonly used in bug localization research. Results The results show that information-theoretic IR methods significantly outperform classical IR methods, providing a semantically aware, yet, computationally efficient solution for bug localization in large and complex software systems. (A replication package is available at: http://seel.cse.lsu.edu/data/ist17.zip). Conclusions Information-theoretic co-occurrence methods provide \u201cjust enough semantics\u201d necessary to establish relations between bug reports and code artifacts, achieving a balance between simple lexical methods and computationally-expensive semantic IR methods that require substantial amounts of data to function properly.", "datasets": ""}, {"title": "Machine translation-based bug localization technique for bridging lexical gap", "authors": "Xiao Yan, Keung Jacky, Bennin Kwabena E., Mi Qing", "year": 2018, "classification": "Learning-based bug localization", "tags": ["deep learning"], "links": "https://doi.org/10.1016/j.infsof.2018.03.003", "CCF": "B\u7c7b\u671f\u520a", "conference": "IST", "abstract": "Context: The challenge of locating bugs in mostly large-scale software systems has led to the development of bug localization techniques. However, the lexical mismatch between bug reports and source codes degrades the performances of existing information retrieval or machine learning-based approaches. Objective: To bridge the lexical gap and improve the effectiveness of localizing buggy files by leveraging the extracted semantic information from bug reports and source code. Method: We present BugTranslator, a novel deep learning-based machine translation technique composed of an attention-based recurrent neural network (RNN) Encoder-Decoder with long short-term memory cells. One RNN encodes bug reports into several context vectors that are decoded by another RNN into code tokens of buggy files. The technique studies and adopts the relevance between the extracted semantic information from bug reports and source files. Results: The experimental results show that BugTranslator outperforms a current state-of-the-art word embedding technique on three open-source projects with higher MAP and MRR. The results show that BugTranslator can rank actual buggy files at the second or third places on average. Conclusion: BugTranslator distinguishes bug reports and source code into different symbolic classes and then extracts deep semantic similarity and relevance between bug reports and the corresponding buggy files to bridge the lexical gap at its source, thereby further improving the performance of bug localization.", "datasets": ""}, {"title": "On the Value of Bug Reports for Retrieval-Based Bug Localization", "authors": "Lawrie Dawn, Binkley Dave", "year": 2018, "classification": "Empirical study", "tags": ["RNN", "LSTM"], "links": "https://doi.org/10.1109/ICSME.2018.00048", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICSME", "abstract": "Software engineering researchers have been applying tools and techniques from information retrieval (IR) to problems such as bug localization to lower the manual effort required to perform maintenance tasks. The central challenge when using an IR-based tool is the formation of a high-quality query. When performing bug localization, one easily accessible source of query words is the bug report. A recent paper investigated the sufficiency of this source by using a genetic algorithm (GA) to build high quality queries. Unfortunately, the GA in essence 'cheats' as it makes use of query performance when evolving a good query. This raises the question, is it feasible to attain similar results without 'cheating?' One approach to providing cheat-free queries is to employ automatic summarization. The performance of the resulting summaries calls into question the sufficiency of the bug reports as a source of query words. To better understand the situation, Information Need Analysis (INA) is applied to quantify both how well the GA is performing and, perhaps more importantly, how well a bug report captures the vocabulary needed to perform IR-based bug localization. The results find that summarization shows potential to produce high-quality queries, but it requires more training data. Furthermore, while bug reports provide a useful source of query words, they are rather limited and thus query expansion techniques, perhaps in combination with summarization, will likely produce higher-quality queries.", "datasets": ""}, {"title": "Poster: Improving Bug Localization with Report Quality Dynamics and Query Reformulation", "authors": "Rahman Mohammad Masudur, Roy Chanchai K.", "year": 2018, "classification": "Query reformulation", "tags": ["empirical study"], "links": "https://doi.org/10.1145/3183440.3195003", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ICSE", "abstract": "Recent findings from a user study suggest that IR-based bug localization techniques do not perform well if the bug report lacks rich structured information such as relevant program entity names. On the contrary excessive structured information such as stack traces in the bug report might always not be helpful for the automated bug localization. In this paper, we conduct a large empirical study using 5,500 bug reports from eight subject systems and replicating three existing studies from the literature. Our findings (1) empirically demonstrate how quality dynamics of bug reports affect the performances of IR-based bug localization, and (2) suggest potential ways (e.g., query reformulations) to overcome such limitations.", "datasets": ""}, {"title": "STRICT: Information Retrieval Based Search Term Identification for Concept Location", "authors": "Rahman Mohammad Masudur, Roy Chanchal K.", "year": 2018, "classification": "IR-based bug localization", "tags": ["concern localization", "search term identification"], "links": "https://doi.org/10.1109/SANER.2017.7884611", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "SANER", "abstract": "During maintenance, software developers deal with numerous change requests that are written in an unstructured fashion using natural language. Such natural language texts illustrate the change requirement involving various domain related concepts. Software developers need to find appropriate search terms from those concepts so that they could locate the possible locations in the source code using a search technique. Once such locations are identified, they can implement the requested changes there. Studies suggest that developers often perform poorly in coming up with good search terms for a change task. In this paper, we propose a novel technique-STRICT-that automatically identifies suitable search terms for a software change task by analyzing its task description using two information retrieval (IR) techniques-TextRank and POSRank. These IR techniques determine a term's importance based on not only its co-occurrences with other important terms but also its syntactic relationships with them. Experiments using 1,939 change requests from eight subject systems report that STRICT can identify better quality search terms than baseline terms from 52%-62% of the requests with 30%-57% Top-10 retrieval accuracy which are promising. Comparison with two state-of-the-art techniques not only validates our empirical findings and but also demonstrates the superiority of our technique.", "datasets": ""}, {"title": "The Impact of IR-based Classifier Configuration on the Performance and the Effort of Method-Level Bug Localization", "authors": "Tantithamthavorn Chakkrit, Lemma Abebe Surafel, Hassan Ahmed E., Ihara Akinori, Matsumoto Kenichi", "year": 2018, "classification": "Empirical study", "tags": ["empirical study", "method level"], "links": "https://doi.org/10.1016/j.infsof.2018.06.001", "CCF": "B\u7c7b\u671f\u520a", "conference": "IST", "abstract": "Context: IR-based bug localization is a classifier that assists developers in locating buggy source code entities (e.g., files and methods) based on the content of a bug report. Such IR-based classifiers have various parameters that can be configured differently (e.g., the choice of entity representation). Objective: In this paper, we investigate the impact of the choice of the IR-based classifier configuration on the top-k performance and the required effort to examine source code entities before locating a bug at the method level. Method: We execute a large space of classifier configuration, 3172 in total, on 5266 bug reports of two software systems, i.e., Eclipse and Mozilla. Results: We find that (1) the choice of classifier configuration impacts the top-k performance from 0.44% to 36% and the required effort from 4395 to 50,000 LOC; (2) classifier configurations with similar top-k performance might require different efforts; (3) VSM achieves both the best top-k performance and the least required effort for method-level bug localization; (4) the likelihood of randomly picking a configuration that performs within 20% of the best top-k classifier configuration is on average 5.4% and that of the least effort is on average 1%; (5) configurations related to the entity representation of the analyzed data have the most impact on both the top-k performance and the required effort; and (6) the most efficient classifier configuration obtained at the method-level can also be used at the file-level (and vice versa). Conclusion: Our results lead us to conclude that configuration has a large impact on both the top-k performance and the required effort for method-level bug localization, suggesting that the IR-based configuration settings should be carefully selected and the required effort metric should be included in future bug localization studies.", "datasets": ""}, {"title": "A Statement Level Bug Localization Technique using Statement Dependency Graph", "authors": "Rahman Shanto, Rahman Md Mostafijur, Sakib Kazi", "year": 2017, "classification": "IR-based bug localization", "tags": ["statement level", "VSM"], "links": "https://doi.org/10.5220/0006261901710178", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Existing bug localization techniques suggest source code methods or classes as buggy which require manual investigations to find the buggy statements. Considering that issue, this paper proposes Statement level Bug Localization (SBL), which can effectively identify buggy statements from the source code. In SBL, relevant buggy methods are ranked using dynamic analysis followed by static analysis of the source code. For each ranked buggy method, a Method Statement Dependency Graph (MSDG) is constructed where each statement acts as a node of the graph. Since each of the statements contains few information, it is maximized by combining the contents of each node and its predecessor nodes in MSDG, resulting a Node Predecessor-node Dependency Graph (NPDG). To identify relevant statements for a bug, similarity is measured between the bug report and each node of the NPDG using Vector Space Model (VSM). Finally, the buggy statements are ranked based on the similarity scores. Rigorous experiments on three open source projects named as Eclipse, SWT and PasswordProtector show that SBL localizes the buggy statements with reasonable accuracies.", "datasets": ""}, {"title": "Augmenting Bug Localization with Part-of-Speech and Invocation", "authors": "Zhou Yu, Tong Yanxiang, Chen Taolue, Han Jin", "year": 2017, "classification": "IR-based bug localization", "tags": ["call dependency", "part of speech"], "links": "https://doi.org/10.1142/S0218194017500346", "CCF": "C\u7c7b\u671f\u520a", "conference": "IJSEKE", "abstract": "Bug localization represents one of the most expensive, as well as time-consuming, activities during software maintenance and evolution. To alleviate the workload of developers, numerous methods have been proposed to automate this process and narrow down the scope of reviewing buggy files. In this paper, we present a novel buggy source-file localization approach, using the information from both the bug reports and the source files. We leverage the part-of-speech features of bug reports and the invocation relationship among source files. We also integrate an adaptive technique to further optimize the performance of the approach. The adaptive technique discriminates Top 1 and Top N recommendations for a given bug report and consists of two modules. One module is to maximize the accuracy of the first recommended file, and the other one aims at improving the accuracy of the fixed defect file list. We evaluate our approach on six large-scale open source projects, i.e. ASpectJ, Eclipse, SWT, Zxing, Birt and Tomcat. Compared to the previous work, empirical results show that our approach can improve the overall prediction performance in all of these cases. Particularly, in terms of the Top 1 recommendation accuracy, our approach achieves an enhancement from 22.73% to 39.86% for ASpectJ, from 24.36% to 30.76% for Eclipse, from 31.63% to 46.94% for SWT, from 40% to 55% for ZXing, from 7.97% to 21.99% for Birt, and from 33.37% to 38.90% for Tomcat.", "datasets": ""}, {"title": "Bug localization with combination of deep learning and information retrieval", "authors": "Lam An Ngoc, Nguyen Anh Tuan, Nguyen Hoan Anh, Nguyen Tien N.", "year": 2017, "classification": "Learning-based bug localization", "tags": ["deep learning", "DNN", "rVSM"], "links": "https://doi.org/10.1109/ICPC.2017.24", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICPC", "abstract": "The automated task of locating the potential buggy files in a softwareproject given a bug report is called bug localization. Buglocalization helps developers focus on crucial files. However, theexisting automated bug localization approaches face a key challenge, called lexical mismatch. Specifically, the terms used in bug reportsto describe a bug are different from the terms and code tokens used insource files. To address that, we present a novel approach that usesdeep neural network (DNN) in combination with rVSM, an informationretrieval (IR) technique. rVSM collects the feature on the textualsimilarity between bug reports and source files. DNN is used to learnto relate the terms in bug reports to potentially different codetokens and terms in source files. Our empirical evaluation onreal-world bug reports in the open-source projects shows that DNN andIR complement well to each other to achieve higher bug localizationaccuracy than individual models. Importantly, our new model, DNNLOC, with a combination of the features built from DNN, rVSM, and project'sbug-fixing history, achieves higher accuracy than the state-of-the-artIR and machine learning techniques. In half of the cases, it iscorrect with just a single suggested file. In 66% of the time, acorrect buggy file is in the list of three suggested files. With 5suggested files, it is correct in almost 70% of the cases.", "datasets": ""}, {"title": "Enhancing the unified features to locate buggy files by exploiting the sequential nature of source code", "authors": "Huo Xuan, Li Ming", "year": 2017, "classification": "Learning-based bug localization", "tags": ["CNN", "deep learning", "LSTM"], "links": "https://doi.org/10.24963/ijcai.2017/265", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "IJCAI", "abstract": "Bug reports provide an effective way for end-users to disclose potential bugs hidden in a software system, while automatically locating the potential buggy source files according to a bug report remains a great challenge in software maintenance. Many previous approaches represent bug reports and source code from lexical and structural information correlated their relevance by measuring their similarity, and recently a CNN-based model is proposed to learn the unified features for bug localization, which overcomes the difficulty in modeling natural and programming languages with different structural semantics. However, previous studies fail to capture the sequential nature of source code, which carries additional semantics beyond the lexical and structural terms and such information is vital in modeling program functionalities and behaviors. In this paper, we propose a novel model LS-CNN, which enhances the unified features by exploiting the sequential nature of source code. LS-CNN combines CNN and LSTM to extract semantic features for automatically identifying potential buggy source code according to a bug report. Experimental results on widely-used software projects indicate that LS-CNN significantly outperforms the state-of-the-art methods in locating buggy files.", "datasets": ""}, {"title": "Exploring Metadata in Bug Reports for Bug Localization", "authors": "Zhang Xiaofei, Yao Yuan, Wang Yaojing, Xu Feng, Lu Jian", "year": 2017, "classification": "IR-based bug localization", "tags": ["metadata"], "links": "https://doi.org/10.1109/APSEC.2017.39", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "APSEC", "abstract": "Information retrieval methods have been proposed to help developers locate related buggy source files for a given bug report. The basic assumption of these methods is that the bug description in a bug report should be textually similar to its buggy source files. However, the metadata (such as the component and version information) in bug reports is largely ignored by these methods. In this paper, we propose to explore the metadata for the bug localization task. In particular, we first apply a generative model to locate buggy source files based on the bug descriptions, and then propose to add the available metadata in bug reports into the localization process. Experimental evaluations on several software projects indicate that the metadata is useful to improve the localization accuracy and that the proposed bug localization method outperforms several existing methods.", "datasets": ""}, {"title": "How Does Execution Information Help with Information-Retrieval Based Bug Localization?", "authors": "Dao Tung, Zhang Lingming, Meng Na", "year": 2017, "classification": "Empirical study", "tags": ["empirical study", "execution Information"], "links": "https://doi.org/10.1109/ICPC.2017.29", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICPC", "abstract": "Bug localization is challenging and time-consuming. Given a bug report, a developer may spend tremendous time comprehending the bug description together with code in order to locate bugs. To facilitate bug report comprehension, information retrieval (IR)-based bug localization techniques have been proposed to automatically search for and rank potential buggy code elements (i.e., classes or methods). However, these techniques do not leverage any dynamic execution information of buggy programs. In this paper, we perform the first systematic study on how dynamic execution information can help with static IR-based bug localization. More specifically, with the fixing patches and bug reports of 157 real bugs, we investigated the impact of various execution information (i.e. coverage, slicing, and spectrum) on three IR-based techniques: the baseline technique, BugLocator, and BLUiR. Our experiments demonstrate that both the coverage and slicing information of failed tests can effectively reduce the search space and improve IR-based techniques at both class and method levels. Using additional spectrum information can further improve bug localization at the method but not the class level. Some of our investigated ways of augmenting IR-based bug localization with execution information even outperform a state-of-the-art technique, which merges spectrum with an IR-based technique in a complicated way. Different from prior work, by investigating various easy-to-understand ways to combine execution information with IR-based techniques, this study shows for the first time that execution information can generally bring considerable improvement to IR-based bug localization.", "datasets": ""}, {"title": "Improved bug localization based on code change histories and bug reports", "authors": "Youm Klaus Changsun, Ahn June, Lee Eunseok", "year": 2017, "classification": "IR-based bug localization", "tags": ["change history", "similar report", "stack trace", "structure"], "links": "https://doi.org/10.1016/j.infsof.2016.11.002", "CCF": "B\u7c7b\u671f\u520a", "conference": "IST", "abstract": "Context Several issues or defects in released software during the maintenance phase are reported to the development team. It is costly and time-consuming for developers to precisely localize bugs. Bug reports and the code change history are frequently used and provide information for identifying fault locations during the software maintenance phase. Objective It is difficult to standardize the style of bug reports written in natural languages to improve the accuracy of bug localization. The objective of this paper is to propose an effective information retrieval-based bug localization method to find suspicious files and methods for resolving bugs. Method In this paper, we propose a novel information retrieval-based bug localization approach, termed Bug Localization using Integrated Analysis (BLIA). Our proposed BLIA integrates analyzed data by utilizing texts, stack traces and comments in bug reports, structured information of source files, and the source code change history. We improved the granularity of bug localization from the file level to the method level by extending previous bug repository data. Results We evaluated the effectiveness of our approach based on experiments using three open-source projects, namely AspectJ, SWT, and ZXing. In terms of the mean average precision, on average our approach improves the metric of BugLocator, BLUiR, BRTracer, AmaLgam and the preliminary version of BLIA by 54%, 42%, 30%, 25% and 15%, respectively, at the file level of bug localization. Conclusion Compared with prior tools, the results showed that BLIA outperforms these other methods. We analyzed the influence of each score of BLIA from various combinations based on the analyzed information. Our proposed enhancement significantly improved the accuracy. To improve the granularity level of bug localization, a new approach at the method level is proposed and its potential is evaluated.", "datasets": ""}, {"title": "Improving Bug Localization with an Enhanced Convolutional Neural Network", "authors": "Xiao Yan, Keung Jacky", "year": 2017, "classification": "Learning-based bug localization", "tags": ["deep learning", "CNN", "word embedding", "dataset"], "links": "https://doi.org/10.1109/APSEC.2017.40", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "APSEC", "abstract": "Background: Localizing buggy files automatically speeds up the process of bug fixing so as to improve the efficiency and productivity of software quality teams. There are other useful semantic information available in bug reports and source code, but are mostly underutilized by existing bug localization approaches. Aims: We propose DeepLocator, a novel deep learning based model to improve the performance of bug localization by making full use of semantic information. Method: DeepLocator is composed of an enhanced CNN (Convolutional Neural Network) proposed in this study considering bug-fixing experience, together with a new rTF-IDuF method and pretrained word2vec technique. DeepLocator is then evaluated on over 18,500 bug reports extracted from AspectJ, Eclipse, JDT, SWT and Tomcat projects. Results: The experimental results show that DeepLocator achieves 9.77% to 26.65% higher Fmeasure than the conventional CNN and 3.8% higher MAP than a state-of-the-art method HyLoc using less computation time. Conclusion: DeepLocator is capable of automatically connecting bug reports to the corresponding buggy files and successfully achieves better performance based on a deep understanding of semantics in bug reports and source code.", "datasets": "https://github.com/yanxiao6/BugLocalization-dataset"}, {"title": "Locating relevant source files for bug reports using textual analysis", "authors": "Gharibi Reza, Rasekh Amir Hossein, Sadreddini Mohammad Hadi", "year": 2017, "classification": "IR-based bug localization", "tags": ["classification"], "links": "https://doi.org/10.1109/CSICSSE.2017.8320119", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Bug reports are an important part of software project's life cycle since they help improve the software's quality. However, in well-known systems, the huge number of bug reports make it difficult for the developer team to efficiently locate the bug and then assign it to be fixed. To solve this issue, various bug localization techniques have been proposed to rank all the source files of a project with respect to how likely they are to contain a bug. This makes the source files' search space smaller and helps developers to find relevant source files quicker. In this paper, we propose a three component bug localization approach which leverages different textual properties of bug reports and source files as well as the relations between previously fixed bug reports and a newly received one. Our approach uses information retrieval, textual matching, and multi-label classification to improve the performance of bug localization. We evaluate our approach on two open source software projects (i.e. SWT and ZXing) to examine its performance. Experimental results show that our approach can rank appropriate source files for more than 80% of bugs in top 10 for these projects and also improve the MRR and MAP values compared to two existing bug localization tools, BugLocator and BLUiR.", "datasets": ""}, {"title": "On the influence of program constructs on bug localization effectiveness: A study of 20 C\\# projects", "authors": "Garnier Marcelo, Ferreira Isabella, Garcia Alessandro", "year": 2017, "classification": "Empirical study", "tags": ["empirical study"], "links": "https://doi.org/10.1186/s40411-017-0040-2", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": " Software projects often reach hundreds or thousands of files. Therefore, manually searching for code elements that should be changed to fix a failure is a difficult task. Static bug localization techniques provide cost-effective means of finding files related to the failure described in a bug report. Structured information retrieval (IR) has been successfully applied by techniques such as BLUiR, BLUiR+, and AmaLgam. However, there are significant shortcomings on how these techniques were evaluated. First, virtually all evaluations have been limited to very few projects written in only one object-oriented programming language, particularly Java. Second, it might be that particular constructs of different programming languages, such as C#, play a role on the effectiveness of bug localization techniques. However, little is known about this phenomenon. Third, the experimental setup for most of the bug localization studies make simplistic assumptions that do not hold on real-world scenarios, thereby raising doubts about the reported effectiveness of existing techniques. In this article, we evaluate BLUiR, BLUiR+, and AmaLgam on 20 C# projects, addressing the aforementioned shortcomings from previous studies. Then, we extend AmaLgam\u2019s algorithm to understand if structured information retrieval can benefit from the use of a wider range of program constructs, including C# constructs inexistent in Java. We also perform an analysis of the influence of program constructs to bug localization effectiveness using Principal Component Analysis (PCA). Our analysis points to Methods and Classes as the constructs that contribute the most to the effectiveness of bug localization. It also reveals a significant contribution from Properties and String literals, constructs not considered in previous studies. Finally, we evaluate the effects of changing the emphasis on particular constructs by making another extension to AmaLgam\u2019s algorithm, enabling the specification of different weights for each construct. Our results show that fine-tuning these weights may increase the effectiveness of bug localization in projects structured with a specific programming language, such as C#.", "datasets": ""}, {"title": "Revisiting the Practical Use of Automated Software Fault Localization Techniques", "authors": "Ang Aaron, Perez Alexandre, Deursen Arie Van, Abreu Rui", "year": 2017, "classification": "IR-based bug localization", "tags": ["empirical study"], "links": "https://doi.org/10.1109/ISSREW.2017.68", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ISSRE", "abstract": "In the last two decades, a great amount of effort has been put in researching automated debugging techniques to support developers in the debugging process. However, in a widely cited user study published in 2011, Parnin and Orso found that research in automated debugging techniques made assumptions that do not hold in practice, and suggested four research directions to remedy this: Absolute evaluation metrics, result comprehension, ecosystems, and user studies.In this study, we revisit the research directions proposed by the authors, offering an overview of the progress that the research community has made in addressing them since 2011. We observe that new absolute evaluation metrics and result comprehension techniques have been proposed, while research in ecosystems and user studies remains mostly unexplored. We analyze what is hard about these unexplored directions and propose avenues for further research in the area of fault localization.", "datasets": ""}, {"title": "The IlmSeven Dataset", "authors": "Rath Michael, Rempel Patrick, Mader Patrick", "year": 2017, "classification": "Datasets", "tags": ["dataset"], "links": "https://doi.org/10.1109/RE.2017.18", "CCF": "B\u7c7b\u671f\u520a", "conference": "RE", "abstract": "Developing new ideas and algorithms or comparing new findings in the field of requirements engineering and management implies a dataset to work with. Collecting the required data is time consuming, tedious, and may involve unforeseen difficulties. The need for datasets often forces re-searchers to collect data themselves in order to evaluate their findings. However, comparing results with other publications is especially difficult on proprietary datasets. A big obstacle is the reproduction of a previously used dataset, which may include subtle preprocessing steps not explicitly mentioned by the original authors. Providing a predefined dataset avoids these problems. It establishes a common baseline and enables direct comparison for benchmarking. This paper provides a well defined dataset consisting of seven open source software projects. It contains a large number of typed development artifacts and links between them. Enriched with additional metadata, such as time stamps, versions, and component information, the dataset allows answering a broad range of research questions.", "datasets": "https://goo.gl/3qCwfw"}, {"title": "Using Observed Behavior to Reformulate Queries during Text Retrieval-based Bug Localization", "authors": "Chaparro Oscar, Florez Juan Manuel, Marcus Andrian", "year": 2017, "classification": "Query reformulation", "tags": ["query reformulation"], "links": "https://doi.org/10.1109/ICSME.2017.100", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICSME", "abstract": "Text Retrieval (TR)-based approaches for bug localization rely on formulating an initial query based on a bug report. Often, the query does not return the buggy software artifacts at or near the top of the list (i.e., it is a low-quality query). In such cases, the query needs reformulation. Existing research on supporting developers in the reformulation of queries focuses mostly on leveraging relevance feedback from the user or expanding the original query with additional information (e.g., adding synonyms). In many cases, the problem with such low-quality queries is the presence of irrelevant terms (i.e., noise) and previous research has shown that removing such terms from the queries leads to substantial improvement in code retrieval. Unfortunately, the current state of research lacks methods to identify the irrelevant terms. Our research aims at addressing this problem and our conjecture is that reducing a low-quality query to only the terms describing the Observed Behavior (OB) can improve TR-based bug localization. To verify our conjecture, we conducted an empirical study using bug data from 21 open source systems to reformulate 451 low-quality queries. We compare the accuracy achieved by four TR-based bug localization approaches at three code granularities (i.e., files, classes, and methods), when using the complete bug reports as queries versus a reduced version corresponding to the OB only. The results show that the reformulated queries improve TR-based bug localization for all approaches by 147.4% and 116.6% on average, in terms of MRR and MAP, respectively. We conclude that using the OB descriptions is a simple and effective technique to reformulate low-quality queries during TR-based bug localization.", "datasets": ""}, {"title": "Will this localization tool be effective for this bug? Mitigating the impact of unreliability of information retrieval based bug localization tools", "authors": "Le Tien Duy B., Thung Ferdian, Lo David", "year": 2017, "classification": "Empirical study", "tags": ["effectiveness prediction"], "links": "https://doi.org/10.1007/s10664-016-9484-y", "CCF": "\u672a\u77e5", "conference": "EMSE", "abstract": "Information retrieval (IR) based bug localization approaches process a textual bug report and a collection of source code files to find buggy files. They output a ranked list of files sorted by their likelihood to contain the bug. Recently, several IR-based bug localization tools have been proposed. However, there are no perfect tools that can successfully localize faults within a few number of most suspicious program elements for every single input bug report. Therefore, it is difficult for developers to decide which tool would be effective for a given bug report. Furthermore, for some bug reports, no bug localization tools would be useful. Even a state-of-the-art bug localization tool outputs many ranked lists where buggy files appear very low in the lists. This potentially causes developers to distrust bug localization tools. In this work, we build an oracle that can automatically predict whether a ranked list produced by an IR-based bug localization tool is likely to be effective or not. We consider a ranked list to be effective if a buggy file appears in the top-N position of the list. If a ranked list is unlikely to be effective, developers do not need to waste time in checking the recommended files one by one. In such cases, it is better for developers to use traditional debugging methods or request for further information to localize bugs. To build this oracle, our approach extracts features that can be divided into four categories: score features, textual features, topic model features, and metadata features. We build a separate prediction model for each category, and combine them to create a composite prediction model which is used as the oracle. We name this solution APRILE, which stands for Automated PRediction of IR-based Bug Localization\u2019s Effectiveness. We further integrate APRILE with two other components that are learned using our bagging-based ensemble classification (BEC) method. We refer to the extension of APRILE as APRILE +. We have evaluated APRILE + to predict the effectiveness of three state-of-the-art IR-based bug localization tools on more than three thousands bug reports from AspectJ, Eclipse, SWT, and Tomcat. APRILE + can achieve an average precision, recall, and F-measure of 77.61 %, 88.94 %, and 82.09 %, respectively. Furthermore, APRILE + outperforms a baseline approach by Le and Lo and APRILE by up to a 17.43 % and 10.51 % increase in F-measure respectively.", "datasets": ""}, {"title": "A learning-to-rank based fault localization approach using likely invariants", "authors": "Le Tien Duy B., Lo David, Le Goues Claire, Grunske Lars", "year": 2016, "classification": "IR-based bug localization", "tags": ["learn to rank"], "links": "https://doi.org/10.1145/2931037.2931049", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ISSTA", "abstract": "Debugging is a costly process that consumes much developer time and energy. To help reduce debugging effort, many studies have proposed various fault localization approaches. These approaches take as input a set of test cases (some failing, some passing) and produce a ranked list of program elements that are likely to be the root cause of the failures (i.e., failing test cases). In this work, we propose Savant, a new fault localization approach that employs a learning-to-rank strategy, using likely invariant diffs and suspiciousness scores as features, to rank methods based on their likelihood of being a root cause of a failure. Savant has four steps: method clustering and test case selection, invariant mining, feature extraction, and method ranking. At the end of these four steps, Savant produces a short ranked list of potentially buggy methods. We have evaluated Savant on 357 real-life bugs from 5 programs from the Defects4J benchmark. We find that, on average, Savant can identify the correct buggy method for 63.03, 101.72, and 122 bugs at the top 1, 3, and 5 positions in the produced ranked lists. We have compared Savant against several state-of-the-art spectrum-based fault localization baselines. We show that Savant can successfully locate 57.73%, 56.69%, and 43.13% more bugs at top 1, top 3, and top 5 positions than the best performing baseline, respectively.", "datasets": ""}, {"title": "A Strategy to Determine When to Stop Using Automatic Bug Localization", "authors": "Shi Zhendong, Keung Jacky, Bennin Kwabena Ebo, Limsettho Nachai, Song Qinbao", "year": 2016, "classification": "Empirical study", "tags": ["effectiveness prediction"], "links": "https://doi.org/10.1109/COMPSAC.2016.39", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "COMPSAC", "abstract": "Information retrieval based automatic bug localization techniques provide developers a ranked list of suspicious buggy source entities to aid locate the ones needed to be modified and to fix the bug. However, it is unavoidable that some buggy entities are ranked low in the result list using these automatic techniques. We assume a bug localization process to address this challenge. Each time a source code entity in the ranked list is examined, the developers will have the option as to whether to continue examining the automatic bug localization result, or simply switch to using a conventional localization approach. We propose a new evaluation metric called ETC (Expected Time Cost) in the localization process, which includes the time cost of using the conventional approach. Under our assumptions, we derived simple criteria to minimize ETC. We compared the time cost of a state-of-art automatic localization method, BugLocator, with and without using our strategy in two projects. The result shows that using our proposed strategy combining both automatic localization technique together with conventional approach performs better than using only either the automatic localization technique or the conventional approach.", "datasets": ""}, {"title": "AmaLgam+: Composing rich information sources for accurate bug localization", "authors": "Wang Shaowei, Lo David", "year": 2016, "classification": "IR-based bug localization", "tags": ["structure", "version history", "similar report", "stack trace", "reporter"], "links": "https://doi.org/10.1002/smr.1801", "CCF": "\u672a\u77e5", "conference": "JSEP", "abstract": "During the evolution of a software system, a large number of bug reports are submitted. Locating the source code files that need to be fixed to resolve the bugs is a challenging problem. Thus, there is a need for a technique that can automatically figure out these buggy files. A number of bug localization solutions that take in a bug report and output a ranked list of files sorted based on their likelihood to be buggy have been proposed in the literature. However, the accuracy of these tools still needs to be improved. In this paper, to address this need, we propose AmaLgam+, which is a method for locating relevant buggy files that puts together fives sources of information, namely, version history, similar reports, structure, stack traces, and reporter information. We perform a large-scale experiment on four open source projects, namely, AspectJ, Eclipse, SWT, and ZXing to localize more than 3000 bugs. We compare AmaLgam + with several state-of-the-art approaches including AmaLgam, BLUiR+, BRtracer+, BugLocator, and TFIDF-DHbPd. These approaches leverage one or several of the sources of information analyzed by AmaLgam+, but not all of them. On average, AmaLgam + achieves a 6.0% improvement over AmaLgam, which merges three sources of information, in terms of Mean Average Precision (MAP). For AspectJ and Eclipse datasets, in which there are many bug reports with stack traces and many reporters submit multiple bug reports, AmaLgam + achieves a 12.0% improvement over AmaLgam in terms of MAP. Compared with the other state-of-the-art approaches, AmaLgam + achieves an improvement of 20.3%, 22.5%, 33.1%, and 73.9% over BLUiR+, BRtracer+, BugLocator, and TFIDF-DHbPd in terms of MAP, respectively. ", "datasets": ""}, {"title": "An Appropriate Method Ranking Approach for Localizing Bugs using Minimized Search Space", "authors": "Rahman Shanto, Sakib Kazi", "year": 2016, "classification": "IR-based bug localization", "tags": ["search space minimization", "method level"], "links": "https://doi.org/10.5220/0005896403030309", "CCF": "\u672a\u77e5", "conference": "ENASE", "abstract": "In automatic software bug localization, source code analysis is usually used to localize the buggy code without manual intervention. However, due to considering irrelevant source code, localization accuracy may get biased. In this paper, a Method level Bug localization using Minimized search space (MBuM) is proposed for improving the accuracy, which considers only the liable source code for generating a bug. The relevant search space for a bug is extracted using the execution trace of the source code. By processing these relevant source code and the bug report, code and bug corpora are generated. Afterwards, MBuM ranks the source code methods based on the textual similarity between the bug and code corpora. To do so, modified Vector Space Model (mVSM) is used which incorporates the size of a method with Vector Space Model. Rigorous experimental analysis using different case studies are conducted on two large scale open source projects namely Eclipse and Mozilla. Experiments show that MBuM outperforms existing bug localization techniques.", "datasets": ""}, {"title": "An Improved Method Level Bug Localization Approach Using Minimized Code Space", "authors": "Rahman Shanto, Rahman Md Mostafijur, Sakib Kazi", "year": 2016, "classification": "IR-based bug localization", "tags": ["search space minimization", "method level"], "links": "https://doi.org/10.1007/978-3-319-56390-9_9", "CCF": "\u672a\u77e5", "conference": "ENASE", "abstract": "In automatic software bug localization, source code classes and methods are commonly used as the unit of suggestions. However, existing techniques consider whole source code to find the buggy locations, which degrades the accuracy of bug localization. In this paper, a Method level Bug localization using Minimized code space (MBuM) has been proposed which improves the accuracy by only considering bug specific source code. Later, this source code is used for identifying the similarity to the bug report. These similarity scores are measured using a modified Vector Space Model (mVSM), and based on that scores MBuM ranks a list of source code methods. The validity of MBuM has been checked by providing theoretical proof using formal methods. Case studies have been performed on two large scale open source projects namely Eclipse and Mozilla, and the results show that MBuM outperforms existing bug localization techniques.", "datasets": ""}, {"title": "From word embeddings to document similarities for improved information retrieval in software engineering", "authors": "Ye Xin, Shen Hui, Ma Xiao, Bunescu Razvan, Liu Chang", "year": 2016, "classification": "Learning-based bug localization", "tags": ["word embedding"], "links": "https://doi.org/10.1145/2884781.2884862", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ICSE", "abstract": "The application of information retrieval techniques to search tasks in software engineering is made difficult by the lexi-cal gap between search queries, usually expressed in natural language (e.g. English), and retrieved documents, usually expressed in code (e.g. programming languages). This is often the case in bug and feature location, community ques-tion answering, or more generally the communication be-tween technical personnel and non-technical stake holders in a software project. In this paper, we propose bridging the lexical gap by projecting natural language statements and code snippets as meaning vectors in a shared representation space. In the proposed architecture, word embeddings are first trained on API documents, tutorials, and reference doc-uments, and then aggregated in order to estimate semantic similarities between documents. Empirical evaluations show that the learned vector space embeddings lead to improvements in a previously explored bug localization task and a newly defined task of linking API documents to computer programming questions.", "datasets": ""}, {"title": "Improved Bug Localization Technique Using Hybrid Information Retrieval Model", "authors": "Gore Alpa, Dutt Choubey Siddharth, Kopal Gangrade\uff0c", "year": 2016, "classification": "IR-based bug localization", "tags": ["VSM", "N-Gram"], "links": "https://doi.org/10.1007/978-3-319-28034-9_16", "CCF": "\u672a\u77e5", "conference": "ICDCIT", "abstract": "The need of bug localization tools and increased popularity of text based IR models to locate the source code files containing bugs is growing continuously. Time and cost required for fixing bugs can be considerably minimized by improving the techniques of reducing the search space from few thousand source code files to a few files. The main contribution of this paper is to propose a Hybrid model based on two existing IR models (VSM and N-gram) for bug localization. In the proposed hybrid model performance is further improved by using word based bigrams. We have also introduced a weighing factor beta \u03b2 to calculate the weighted sum of unigram and bigram and analyzed its accuracy for values ranging from (0\u20131). Using TopN, MRR and MAP measures, we have conducted experiments which show that the proposed hybrid model outperforms some existing state-of-art bug localization techniques", "datasets": ""}, {"title": "Inferring Links between Concerns and Methods with Multi-abstraction Vector Space Model", "authors": "Zhang Yun, Lo David, Xia Xin, Le Tien Duy B., Scanniello Giuseppe, Sun Jianling", "year": 2016, "classification": "IR-based bug localization", "tags": ["concern localization", "topic model", "VSM"], "links": "https://doi.org/10.1109/ICSME.2016.51", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICSME", "abstract": "Concern localization refers to the process of locating code units that match a particular textual description. It takes as input textual documents such as bug reports and feature requests and outputs a list of candidate code units that are relevant to the bug reports or feature requests. Many information retrieval (IR) based concern localization techniques have been proposed in the literature. These techniques typically represent code units and textual descriptions as a bag of tokens at one level of abstraction, e.g., each token is a word, or each token is a topic. In this work, we propose a multi-abstraction concern localization technique named MULAB. MULAB represents a code unit and a textual description at multiple abstraction levels. Similarity of a textual description and a code unit is now made by considering all these abstraction levels. We combine a vector space model and multiple topic models to compute the similarity and apply a genetic algorithm to infer semi-optimal topic model configurations. We have evaluated our solution on 136 concerns from 8 open source Java software systems. The experimental results show that MULAB outperforms the state-of-art baseline PR, which is proposed by Scanniello et al. in terms of effectiveness and rank.", "datasets": ""}, {"title": "Learning Unified Features from Natural and Programming Languages for Locating Buggy Source Code", "authors": "Huo Xuan, Li Ming, Zhou Zhi Hua", "year": 2016, "classification": "Learning-based bug localization", "tags": ["CNN", "deep learning"], "links": "https://www.ijcai.org/Abstract/16/230", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "IJCAI", "abstract": "Bug reports provide an effective way for end-users to disclose potential bugs hidden in a software system, while automatically locating the potential buggy source code according to a bug report remains a great challenge in software maintenance. Many previous studies treated the source code as natural language by representing both the bug report and source code based on bag-of-words feature representations, and correlate the bug report and source code by measuring similarity in the same lexical feature space. However, these approaches fail to consider the structure information of source code which carries additional semantics beyond the lexical terms. Such information is important in modeling program functionality. In this paper, we propose a novel convolutional neural network NP-CNN, which leverages both lexical and program structure information to learn unified features from natural language and source code in programming language for automatically locating the potential buggy source code according to bug report. Experimental results on widely-used software projects indicate that NP-CNN significantly outperforms the state-of-the-art methods in locating the buggy source files.", "datasets": ""}, {"title": "Locating Bugs without Looking Back", "authors": "Dilshener Tezcan, Wermelinger Michel, Yu Yijun", "year": 2016, "classification": "IR-based bug localization", "tags": [], "links": "https://doi.org/10.1007/s10515-017-0226-1", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "MSR", "abstract": "Bug localisation is a core program comprehension task in software maintenance: given the observation of a bug, e.g. via a bug report, where is it located in the source code? Information retrieval (IR) approaches see the bug report as the query, and the source code files as the documents to be retrieved, ranked by relevance. Such approaches have the advantage of not requiring expensive static or dynamic analysis of the code. However, current state-of-the-art IR approaches rely on project history, in particular previously fixed bugs or previous versions of the source code. We present a novel approach that directly scores each current file against the given report, thus not requiring past code and reports. The scoring method is based on heuristics identified through manual inspection of a small sample of bug reports. We compare our approach to eight others, using their own five metrics on their own six open source projects. Out of 30 performance indicators, we improve 27 and equal 2. Over the projects analysed, on average we find one or more affected files in the top 10 ranked files for 76% of the bug reports. These results show the applicability of our approach to software projects without history.", "datasets": ""}, {"title": "Locus: locating bugs from software changes", "authors": "Wen Ming, Wu Rongxin, Cheung Shing Chi", "year": 2016, "classification": "IR-based bug localization", "tags": ["change history"], "links": "https://doi.org/10.1145/2970276.2970359", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ASE", "abstract": "Various information retrieval (IR) based techniques have been proposed recently to locate bugs automatically at the file level. However, their usefulness is often compromised by the coarse granularity of files and the lack of contextual information. To address this, we propose to locate bugs using software changes, which offer finer granularity than files and provide important contextual clues for bug-fixing. We observe that bug inducing changes can facilitate the bug fixing process. For example, it helps triage the bug fixing task to the developers who committed the bug inducing changes or enables developers to fix bugs by reverting these changes. Our study further identifies that change logs and the naturally small granularity of changes can help boost the performance of IR-based bug localization. Motivated by these observations, we propose an IR-based approach Locus to locate bugs from software changes, and evaluate it on six large open source projects. The results show that Locus outperforms existing techniques at the source file level localization significantly. MAP and MRR in particular have been improved, on average, by 20:1% and 20:5%, respectively. Locus is also capable of locating the inducing changes within top 5 for 41:0% of the bugs. The results show that Locus can significantly reduce the number of lines needing to be scanned to locate the bug compared with existing techniques.", "datasets": ""}, {"title": "Multi-level reranking approach for bug localization", "authors": "K\u0131l\u0131n\u00e7 Deniz, Y\u00fccalar Fatih, Boranda\u011f Emin, Aslan Ersin", "year": 2016, "classification": "IR-based bug localization", "tags": ["multi-level reranking"], "links": "https://doi.org/10.1111/exsy.12150", "CCF": "\u672a\u77e5", "conference": "EXSY", "abstract": "Bug fixing has a key role in software quality evaluation. Bug fixing starts with the bug localization step, in which developers use textual bug information to find location of source codes which have the bug. Bug localization is a tedious and time consuming process. Information retrieval requires understanding the programme's goal, coding structure, programming logic and the relevant attributes of bug. Information retrieval (IR) based bug localization is a retrieval task, where bug reports and source files represent the queries and documents, respectively. In this paper, we propose BugCatcher, a newly developed bug localization method based on multi\u2010level re\u2010ranking IR technique. We evaluate BugCatcher on three open source projects with approximately 3400 bugs. Our experiments show that multi\u2010level reranking approach to bug localization is promising. Retrieval performance and accuracy of BugCatcher are better than current bug localization tools, and BugCatcher has the best Top N, Mean Average Precision (MAP) and Mean Reciprocal Rank (MRR) values for all datasets.", "datasets": ""}, {"title": "On the Evaluation of Structured Information Retrieval-Based Bug Localization on 20 C# Projects", "authors": "Garnier Marcelo, Garcia Alessandro", "year": 2016, "classification": "Empirical study", "tags": ["empirical study", "dataset"], "links": "https://doi.org/10.1145/2973839.2973853", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Software projects can grow very rapidly, reaching hundreds or thousands of files in a relatively short time span. Therefore, manually finding the source code parts that should be changed in order to fix a failure is a difficult task. Static bug localization techniques provide cost-effective means of finding files related to the failure described in a bug report. Recently, structured information retrieval (IR) has been used to improve the effectiveness of static bug localization, being successfully applied by techniques such as BLUiR, BLUiR+, and AmaLgam. However, there are some significant shortcomings on how these techniques were evaluated. First, virtually all evaluations have been limited to very few projects written in only one object-oriented programming language, particularly Java. Therefore, the effectiveness of these techniques in other widely-used object-oriented languages such as C# is still unknown. Second, the experimental setup for most of the evaluations make simplistic assumptions that do not hold on real-world scenarios, thereby raising doubts about the reported effectiveness of these techniques. In this paper, we evaluate BLUiR, BLUiR+, and AmaLgam on 20 C# projects, providing a first assessment of these techniques on a previously untested object-oriented language. Moreover, we set up an experiment that addresses the simplistic assumptions commonly present in bug localization studies, thereby providing evidence on how their findings may be biased. Finally, we extend the algorithms of existing techniques in order to understand if structured information retrieval can benefit from the use of a wider range of program constructs, including C# constructs inexistent in Java.", "datasets": "https://mgarnier.github.io/bug_localization/"}, {"title": "Software bug localization using Pachinko Allocation Model", "authors": "Sharma Tanu, Sharma Kapil, Sharma Tapan", "year": 2016, "classification": "IR-based bug localization", "tags": ["PAM"], "links": "https://ieeexplore.ieee.org/abstract/document/7724934", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Bug localization is the process of identifying the elements of source code that require modification to fix the bug. By automating the task of bug localization efficiently, the cost of software can also be reduced. For performing bug localization, many Information Retrieval models have been used in past. In this paper, bug localization has been performed using Pachinko Allocation Model (PAM). PAM is also an IR model, which falls under the category of topic models and has not been used for locating bugs yet. This paper describes the proposed PAM based approach for bug localization at file level. The PAM based approach is compared with LDA based approach and it has been shown that PAM based bug localization performs better as compared to LDA based bug localization. For evaluating the performance of PAM and LDA based approaches, the datasets downloaded from two open source projects, i.e. Rhino and ModeShape, have been used.", "datasets": ""}, {"title": "Using a Distributed Representation of Words in Localizing Relevant Files for Bug Reports", "authors": "Uneno Yukiya, Mizuno Osamu, Choi Eun Hye", "year": 2016, "classification": "Learning-based bug localization", "tags": ["word2vec", "VSM"], "links": "https://doi.org/10.1109/QRS.2016.30", "CCF": "\u672a\u77e5", "conference": "QRS", "abstract": "Once a bug in software is reported, developers have to determine which source files are related to the bug. This process is referred to as bug localization, and an automatic way of bug localization is important to improve developers' productivity. This paper proposes an approach called DrewBL to efficiently localize faulty files for a given bug report using a natural language processing tool, word2vec. In DrewBL, we first build a vector space model named semantic-VSM which represents a distributed representation of words in the bug report and source code files and next compute the relevance between them by feeding the constructed model to word2vec. We also present an approach called CombBL to further improve the accuracy of bug localization which employs not only the proposed DrewBL but also existing bug localization techniques, such as BugLocator based on textual similarity and Bugspots based on bug-fixing history, in a combinational manner. This paper gives our early experimental results to show the effectiveness and efficiency of the proposed approaches using two open source projects.", "datasets": ""}, {"title": "An improved bug localization using structured information retrieval and version history", "authors": "Rahman Shanto, Ganguly Kishan Kumar, Sakib Kazi", "year": 2015, "classification": "IR-based bug localization", "tags": ["structure", "version history", "VSM"], "links": "https://doi.org/10.1109/ICCITechn.2015.7488066", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Locating buggy files is a time consuming and challenging task because defects can deflate from a large variety of sources. So, researchers proposed several automated bug localization techniques where the accuracy can be improved. In this paper, an information retrieval based bug localization technique has been proposed, where buggy files are identified by measuring the similarity between bug report and source code. Besides this, source code structure and frequently changed files are also incorporated to produce a better rank for buggy files. To evaluate the proposed approach, a large-scale experiment on three open source projects, namely SWT, ZXing and Guava has been conducted. The result shows that the proposed approach improves 7% in terms of Mean Reciprocal Rank (MRR) and about 8% for Mean Average Precision (MAP) compared to existing techniques.", "datasets": ""}, {"title": "Automation Framework for Bug Localization using Information Retrieval Techniques", "authors": "Pathak Dhanashree P, Dharavath Srinu", "year": 2015, "classification": "IR-based bug localization", "tags": ["topic model"], "links": "https://doi.org/10.15680/ijircce.2015.0306124", "CCF": "\u672a\u77e5", "conference": "IJIRCCE", "abstract": "Bug Localization is the technique to find the relevant source code entities from a bug report in order to fix that issue. Till date most of bug localization work in industry, at least in the small scale software companies, is done manually. It is a very time consuming activity as it adds on manual efforts to locate the relevant source code. It leads to taking long time to fix the bug which evidently leads to more cost for maintenance. To somewhat lessen this cost one way is to automate the bug localization process in order to somewhat control the time and effort parameters. This strategy has its own limitations but still can show some positivity if we apply information retrieval techniques and consider bug localization as classification problem. This approach will open doors for more research in this area. This paper has suggested some IR techniques as Relational Topic models, Link Importance in Relational Topic Model to achieve the bug localization.", "datasets": ""}, {"title": "Bug Localization Based on Code Change Histories and Bug Reports", "authors": "Youm Klaus Changsun, Ahn June, Kim Jeongho, Lee Eunseok", "year": 2015, "classification": "IR-based bug localization", "tags": ["structure", "version history", "similar report", "stack trace"], "links": "https://doi.org/10.1109/APSEC.2015.23", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "APSEC", "abstract": "A bug report is mainly used to find a fault location in software maintenance. It contains several fields such as summary, description, status and version. The description field includes detail scenario and stack traces if exceptional messages are presented. Recently researchers have proposed several approaches for automatic bug localization by using information retrieval and data mining. We propose BLIA, a statically integrated analysis approach of IR-based bug localization by utilizing texts and stack traces in bug reports, structured information of source files, and source code change histories. We performed experiments on three open source projects, namely AspectJ, SWT and ZXing. Compared with prior tools, our experiment results showed that BLIA outperforms the existing tools in terms of mean average precision. Our approach on average improved the metric of BugLocator, BLUiR, BRTracer and AmaLgam by 34%, 23%, 17% and 8%, respectively.", "datasets": ""}, {"title": "Bug Localization using LDACG Approach", "authors": "Pathak Dhanashree P, Dharavath Srinu", "year": 2015, "classification": "IR-based bug localization", "tags": ["LDA", "call dependency"], "links": "https://doi.org/10.17577/ijertv4is050095", "CCF": "\u672a\u77e5", "conference": "IJERT", "abstract": "Bug Localization is the task of locating the area of source code that requires modification to correct that bug. By automating this task, effort of debugger can be considerably reduced. In past, automated bug localization has been done with the help of many IR(Information Retrieval) models that focused on the semantic information. In this paper, we have proposed LDACG approach for bug localization which focuses on both semantic and structural information. In LDACG approach, bugs are located using an IR model i.e. LDA (Latent Dirichlet Allocation) and Call graph. Then the combined score of both methods is calculated to locate bugs in efficient manner. We have compared LDACG based approach with LDA based approach and it has been found that LDACG approach performs better than LDA approach for bug localization. The performance of both approaches has been evaluated on the datasets downloaded from two open source projects i.e. Rhino and ModeShape.", "datasets": ""}, {"title": "Combining Deep Learning with Information Retrieval to Localize Buggy Files for Bug Reports", "authors": "Lam An Ngoc, Nguyen Anh Tuan, Nguyen Hoan Anh, Nguyen Tien N.", "year": 2015, "classification": "Learning-based bug localization", "tags": ["deep learning", "DNN", "rVSM"], "links": "https://doi.org/10.1109/ASE.2015.73", "CCF": "A\u7c7b\u671f\u520a", "conference": "ASE", "abstract": "Bug localization refers to the automated process of locating the potential buggy files for a given bug report. To help developers focus their attention to those files is crucial. Several existing automated approaches for bug localization from a bug report face a key challenge, called lexical mismatch, in which the terms used in bug reports to describe a bug are different from the terms and code tokens used in source files. This paper presents a novel approach that uses deep neural network (DNN) in combination with rVSM, an information retrieval (IR) technique. rVSM collects the feature on the textual similarity between bug reports and source files. DNN is used to learn to relate the terms in bug reports to potentially different code tokens and terms in source files and documentation if they appear frequently enough in the pairs of reports and buggy files. Our empirical evaluation on real-world projects shows that DNN and IR complement well to each other to achieve higher bug localization accuracy than individual models. Importantly, our new model, HyLoc, with a combination of the features built from DNN, rVSM, and project's bug-fixing history, achieves higher accuracy than the state-of-the-art IR and machine learning techniques. In half of the cases, it is correct with just a single suggested file. Two out of three cases, a correct buggy file is in the list of three suggested files.", "datasets": ""}, {"title": "Comparing Incremental Latent Semantic Analysis Algorithms for Efficient Retrieval from Software Libraries for Bug Localization", "authors": "Rao Shivani, Medeiros Henry, Kak Avinash", "year": 2015, "classification": "IR-based bug localization", "tags": ["incremental framework", "LSI", "version history"], "links": "https://doi.org/10.1145/2693208.2693222", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "The problem of bug localization is to identify the source files related to a bug in a software repository. Information Retrieval (IR) based approaches create an index of the source files and learn a model which is then queried with a bug for the relevant files. In spite of the advances in these tools, the current approaches do not take into consideration the dynamic nature of software repositories. With the traditional IR based approaches to bug localization, the model parameters must be recalculated for each change to a repository. In contrast, this paper presents an incremental framework to update the model parameters of the Latent Semantic Analysis (LSA) model as the data evolves. We compare two state-of-the-art incremental SVD update techniques for LSA with respect to the retrieval accuracy and the time performance. The dataset we used in our validation experiments was created from mining 10 years of version history of AspectJ and JodaTime software libraries.", "datasets": ""}, {"title": "Information retrieval and spectrum based bug localization: better together", "authors": "Le Tien Duy B., Oentaryo Richard J., Lo David", "year": 2015, "classification": "IR-based bug localization", "tags": ["dataset", "program spectrum"], "links": "https://doi.org/10.1145/2786805.2786880", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "FSE/ESEC", "abstract": "Debugging often takes much effort and resources. To help developers debug, numerous information retrieval (IR)- based and spectrum-based bug localization techniques have been proposed. IR-based techniques process textual information in bug reports, while spectrum-based techniques process program spectra (i.e., a record of which program elements are executed for each test case). Both eventually generate a ranked list of program elements that are likely to contain the bug. However, these techniques only consider one source of information, either bug reports or program spectra, which is not optimal. To deal with the limitation of existing techniques, in this work, we propose a new multi-modal technique that considers both bug reports and program spectra to localize bugs. Our approach adaptively creates a bug-specific model to map a particular bug to its possible location, and introduces a novel idea of suspicious 'words that are highly associated to a bug. We evaluate our approach on 157 real bugs from four software systems, and compare it with a state-of-the-art IR-based bug localization method, a state-of-the-art spectrum-based bug localization method, and three state-of-the-art multi-modal feature location methods that are adapted for bug localization. Experiments show that our approach can outperform the baselines by at least 47.62%, 31.48%, 27.78%, and 28.80% in terms of number of bugs successfully localized when a developer inspects 1, 5, and 10 program elements (i.e., Top 1, Top 5, and Top 10), and Mean Average Precision (MAP) respectively.", "datasets": "https://bitbucket.org/amlfse/amldata/downloads/amldata.7z"}, {"title": "Is Learning-to-Rank Cost-Effective in Recommending Relevant Files for Bug Localization?", "authors": "Zhao Fei, Tang Yaming, Yang Yibiao, Lu Hongmin, Zhou Yuming, Xu Baowen", "year": 2015, "classification": "Empirical study", "tags": ["empirical study", "learn to rank"], "links": "https://doi.org/10.1109/QRS.2015.49", "CCF": "\u672a\u77e5", "conference": "QRS", "abstract": "Software bug localization aiming to determine the locations needed to be fixed for a bug report is one of the most tedious and effort consuming activities in software debugging. Learning-to-rank (LR) is the state-of-the-art approach proposed by Ye et al. to recommending relevant files for bug localization. Ye et al.'s experimental results show that the LR approach significantly outperforms previous bug localization approaches in terms of 'precision' and 'accuracy'. However, this evaluation does not take into account the influence of the size of the recommended files on the efficiency in detecting bugs. In practice, developers will generally spend more code inspection effort to detect bugs if larger files are recommended. In this paper, we use six large-scale open-source Java projects to evaluate the LR approach in the context of effort-aware bug localization. Our results, surprisingly, show that, when taking into account the code inspection effort to detect bugs, the LR approach is similar to or even worse than the standard VSM (Vector Space Model), a na\u00efve IR-based bug localization approach.", "datasets": ""}, {"title": "Performance evaluation of information retrieval models in bug localization on the method level", "authors": "Alduailij Mai, Al-Duailej Mona", "year": 2015, "classification": "Empirical study", "tags": ["empirical study", "VSM", "LSI", "LDA", "dataset"], "links": "https://doi.org/10.1109/CTS.2015.7210439", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "This study uses statistical inference to compare the performance of three text models used for bug localization in collaboration systems: Vector Space Model (VSM), Latent Semantic Indexing (LSI), and Latent Dirichlet Analysis (LDA) on the method level. After the three models are compared we confirm that VSM is the superior model. We then, point out which external factors i.e. methods lengths, queries lengths, methods documentation comments, products names and components names mentioned in bug reports affect VSM performance. We conclude that VSM performance is positively correlated with most of the tested factors. We believe our results can be helpful to: (i) text models developers, to understand the strengths and limitations of VSM for future development; (ii) bug localization programmers using classical VSM, to understand improved ways to prepare methods extracted from big data collaboration systems and (iii) bug reporters, to follow the most efficient methods presented in this work in reporting bugs to enhance the information retrieval process.", "datasets": "http://homepages.wmich.edu/\u223cmnn7262/Steps"}, {"title": "Query-based configuration of text retrieval solutions for software engineering tasks", "authors": "Moreno Laura, Bavota Gabriele, Haiduc Sonia, Di Penta Massimiliano, Oliveto Rocco, Russo Barbara, Marcus Andrian", "year": 2015, "classification": "Empirical study", "tags": ["empirical study", "dataset"], "links": "https://doi.org/10.1145/2786805.2786859", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "FSE/ESEC", "abstract": "Text Retrieval (TR) approaches have been used to leverage the textual information contained in software artifacts to address a multitude of software engineering (SE) tasks. However, TR approaches need to be configured properly in order to lead to good results. Current approaches for automatic TR configuration in SE configure a single TR approach and then use it for all possible queries. In this paper, we show that such a configuration strategy leads to suboptimal results, and propose quest, the first approach bringing TR configuration selection to the query level. quest recommends the best TR configuration for a given query, based on a supervised learning approach that determines the TR configuration that performs the best for each query according to its properties. We evaluated quest in the context of feature and bug localization, using a data set with more than 1,000 queries. We found that quest is able to recommend one of the top three TR configurations for a query with a 69% accuracy, on average. We compared the results obtained with the configurations recommended by quest for every query with those obtained using a single TR configuration for all queries in a system and in the entire data set. We found that using quest we obtain better results than with any of the considered TR configurations.", "datasets": "http://www.utdallas.edu/~lmorenoc/research/fse2015-quest/"}, {"title": "Towards A Novel Approach for Defect Localization Based on Part-of-Speech and Invocation", "authors": "Tong Yanxiang, Zhou Yu, Fang Lisheng, Chen Taolue", "year": 2015, "classification": "IR-based bug localization", "tags": ["call dependency", "part of speech"], "links": "https://doi.org/10.1145/2875913.2875919", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Given a corpus of bug reports, software developers must read various descriptive sentences in order to identify corresponding buggy source files which potentially result in the defects. This process itself represents one of the most expensive, as well as time-consuming, activities during software maintenance and evolution. To alleviate the workload of developers, many methods have been proposed to automate this process and narrow down the scope of reviewing buggy files. In this paper, we present a novel buggy source file localization approach, leveraging both a part-of-speech based weighting strategy and the invocation relationship among source files. We also integrate an adaptive technique to strengthen the optimization of the performance. The adaptive technique consists of two modules. One is to maximize the accuracy of the first recommended file, and the other aims at improving the accuracy of the fixed defect file list. We evaluate our approach on three large-scale open source projects, i.e., ASpectJ, Eclipse, and SWT. Compared with the baseline work, our approach can improve 17.13%, 6.29% and 3.15% on top 1, top 5 and top 10 respectively for ASpectJ, 6.40%, 4.94% and 4.39% on top 1, top 5 and top 10 respectively for Eclipse, and 15.31%, 8.16% and 5.10% on top 1, top 5 and top 10 respectively for SWT.", "datasets": ""}, {"title": "BOAT: an experimental platform for researchers to comparatively and reproducibly evaluate bug localization techniques", "authors": "Wang Xinyu, Lo David, Xia Xin, Wang Xingen, Kochhar Pavneet Singh, Tian Yuan, Yang Xiaohu, Li Shanping, Sun Jianling, Zhou Bo", "year": 2014, "classification": "Tool", "tags": ["experimental platform"], "links": "https://doi.org/10.1145/2591062.2591066", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ICSE", "abstract": "Bug localization refers to the process of identifying source code files that contain defects from descriptions of these de-fects which are typically contained in bug reports. There have been many bug localization techniques proposed in the literature. However, often it is hard to compare these tech-niques since different evaluation datasets are used. At times the datasets are not made publicly available and thus it is dificult to reproduce reported results. Furthermore, some techniques are only evaluated on small datasets and thus it is not clear whether the results are generalizable. Thus, there is a need for a platform that allows various techniques to be compared with one another on a common pool containing a large number of bug reports with known defective source code files. In this paper, we address this need by propos-ing our Bug lOcalization experimental plATform (BOAT). BOAT is an extensible web application that contains thou-sands of bug reports with known defective source code files. Researchers can create accounts in BOAT, upload executa-bles of their bug localization techniques, and see how these techniques perform in comparison with techniques uploaded by other researchers, with respect to some standard eval-uation measures. BOAT is already preloaded with several bug localization techniques and thus researchers can direct-ly compare their newly proposed techniques against these existing techniques. BOAT has been made available online since October 2013, and researchers could access the plat-form at: http://www.vlis.zju.edu.cn/blp. ", "datasets": ""}, {"title": "Boosting Bug-Report-Oriented Fault Localization with Segmentation and Stack-Trace Analysis", "authors": "Wong Chu Pan, Xiong Yingfei, Zhang Hongyu, Hao Dan, Zhang Lu, Mei Hong", "year": 2014, "classification": "IR-based bug localization", "tags": ["segmentation", "stack trace"], "links": "https://doi.org/10.1109/ICSME.2014.40", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICSME", "abstract": "To deal with post-release bugs, many software projects set up public bug repositories for users all over the world to report bugs that they have encountered. Recently, researchers have proposed various information retrieval based approaches to localizing faults based on bug reports. In these approaches, source files are processed as single units, where noise in large files may affect the accuracy of fault localization. Furthermore, bug reports often contain stack-trace information, but existing approaches often treat this information as plain text. In this paper, we propose to use segmentation and stack-trace analysis to improve the performance of bug localization. Specifically, given a bug report, we divide each source code file into a series of segments and use the segment most similar to the bug report to represent the file. We also analyze the bug report to identify possible faulty files in a stack trace and favor these files in our retrieval. According to our empirical results, our approach is able to significantly improve Bug Locator, a representative fault localization approach, on all the three software projects (i.e., Eclipse, AspectJ, and SWT) used in our empirical evaluation. Furthermore, segmentation and stack-trace analysis are complementary to each other for boosting the performance of bug-report-oriented fault localization.", "datasets": ""}, {"title": "BugLocalizer: integrated tool support for bug localization", "authors": "Thung Ferdian, Le Tien Duy B., Kochhar Pavneet Singh, Lo David", "year": 2014, "classification": "Tool", "tags": ["tool"], "links": "https://doi.org/10.1145/2635868.2661678", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "FSE/ESEC", "abstract": "To manage bugs that appear in a software, developers often make use of a bug tracking system such as Bugzilla. Users can report bugs that they encounter in such a system. Whenever a user reports a new bug report, developers need to read the summary and description of the bug report and manually locate the buggy files based on this information. This manual process is often time consuming and tedious. Thus, a number of past studies have proposed bug localization techniques to automatically recover potentially buggy files from bug reports. Unfortunately, none of these techniques are integrated to bug tracking systems and thus it hinders their adoption by practitioners. To help disseminate research in bug localization to practitioners, we develop a tool named BugLocalizer, which is implemented as a Bugzilla extension and builds upon a recently proposed bug localization technique. Our tool extracts texts from summary and description fields of a bug report and source code files. It then computes similarities of the bug report with source code files to find the buggy files. Developers can use our tool online from a Bugzilla web interface by providing a link to a git source code repository and specifying the version of the repository to be analyzed. We have released our tool publicly in GitHub, which is available at: https://github.com/smagsmu/buglocalizer. We have also provided a demo video, which can be accessed at: http://youtu.be/iWHaLNCUjBY.", "datasets": ""}, {"title": "Compositional Vector Space Models for Improved Bug Localization", "authors": "Wang Shaowei, Lo David, Lawall Julia", "year": 2014, "classification": "IR-based bug localization", "tags": ["VSM"], "links": "https://doi.org/10.1109/ICSME.2014.39", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICSME", "abstract": "Software developers and maintainers often need to locate code units responsible for a particular bug. A number of Information Retrieval (IR) techniques have been proposed to map natural language bug descriptions to the associated code units. The vector space model (VSM) with the standard tf-idf weighting scheme (VSM natural ), has been shown to outperform nine other state-of-the-art IR techniques. However, there are multiple VSM variants with different weighting schemes, and their relative performance differs for different software systems. Based on this observation, we propose to compose various VSM variants, modelling their composition as an optimization problem. We propose a genetic algorithm (GA) based approach to explore the space of possible compositions and output a heuristically near-optimal composite model. We have evaluated our approach against several baselines on thousands of bug reports from AspectJ, Eclipse, and SWT. On average, our approach (VSM composite ) improves hit at 5 (Hit@5), mean average precision (MAP), and mean reciprocal rank (MRR) scores of VSM natural by 18.4%, 20.6%, and 10.5% respectively. We also integrate our compositional model with AmaLgam, which is a state-of-art bug localization technique. The resultant model named AmaLgam composite on average can improve Hit@5, MAP, and MRR scores of AmaLgam by 8.0%, 14.4% and 6.5% respectively.", "datasets": ""}, {"title": "Cross-language bug localization", "authors": "Xia Xin, Lo David, Wang Xingen, Zhang Chenyi, Wang Xinyu", "year": 2014, "classification": "IR-based bug localization", "tags": ["cross-language"], "links": "https://doi.org/10.1145/2597008.2597788", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICPC", "abstract": "Bug localization refers to the process of identifying source code files that contain defects from textual descriptions in bug reports. Existing bug localization techniques work on the assumption that bug reports, and identifiers and comments in source code files, are written in the same language (i.e., English). However, software users from non-English speaking countries (e.g., China) often use their native languages (e.g., Chinese) to write bug reports. For this setting, existing studies on bug localization would not work as the terms that appear in the bug reports do not appear in the source code. We refer to this problem as cross-language bug localization. In this paper, we propose a cross-language bug localization algorithm named CrosLocator, which is based on language translation. Since different online translators (e.g., Google and Microsoft translators) have different translation accuracies for various texts, CrosLocator uses multiple translators to convert a non-English textual description of a bug report into English { each bug report would then have multiple translated versions. For each translated version, CrosLocator applies a bug localization technique to rank source code files. Finally, CrosLocator combines the multiple ranked lists of source code files. Our preliminary experiment on Ruby-China shows that CrosLocator could achieve mean reciprocal rank (mrr) and mean average precision (map) scores of up to 0.146 and 0.116, which outperforms a baseline approach by an average of 10% and 12% respectively.", "datasets": ""}, {"title": "Defects4J: A database of existing faults to enable controlled testing studies for Java programs", "authors": "Just Ren\u00e9, Jalali Darioush, Ernst Michael D.", "year": 2014, "classification": "Datasets", "tags": ["dataset"], "links": "https://doi.org/10.1145/2610384.2628055", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ISSTA", "abstract": "Empirical studies in software testing research may not be comparable, reproducible, or characteristic of practice. One reason is that real bugs are too infrequently used in software testing research. Extracting and reproducing real bugs is challenging and as a result hand-seeded faults or mutants are commonly used as a substitute. This paper presents Defects4J, a database and extensible framework providing real bugs to enable reproducible studies in software testing research. The initial version of Defects4J contains 357 real bugs from 5 real-world open source pro- grams. Each real bug is accompanied by a comprehensive test suite that can expose (demonstrate) that bug. Defects4J is extensible and builds on top of each program's version control system. Once a program is configured in Defects4J, new bugs can be added to the database with little or no effort. Defects4J features a framework to easily access faulty and fixed program versions and corresponding test suites. This framework also provides a high-level interface to common tasks in software testing research, making it easy to con- duct and reproduce empirical studies. Defects4J is publicly available at http://defects4j.org.", "datasets": "https://github.com/rjust/defects4j"}, {"title": "It's not a bug, it's a feature: does misclassification affect bug localization?", "authors": "Kochhar Pavneet Singh, Le Tien Duy B., Lo David", "year": 2014, "classification": "Empirical study", "tags": ["empirical study"], "links": "https://doi.org/10.1145/2597073.2597105", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "MSR", "abstract": "Bug localization refers to the task of automatically processing bug reports to locate source code files that are responsible for the bugs. Many bug localization techniques have been proposed in the literature. These techniques are often evaluated on issue reports that are marked as bugs by their reporters in issue tracking systems. However, recent findings by Herzig et al. find that a substantial number of issue reports marked as bugs, are not bugs but other kinds of issues like refactorings, request for enhancement, documentation changes, test case creation, and so on. Herzig et al. report that these misclassifications affect bug prediction, namely the task of predicting which files are likely to be buggy in the future. In this work, we investigate whether these misclas-sifications also affect bug localization. To do so, we analyze issue reports that have been manually categorized by Herzig et al. and apply a bug localization technique to recover a ranked list of candidate buggy files for each issue report. We then evaluate whether the quality of ranked lists of reports reported as bugs is the same as that of real bug reports. Our findings shed light that there is a need for additional cleaning steps to be performed on issue reports before they are used to evaluate bug localization techniques.", "datasets": ""}, {"title": "Learning to Rank Relevant Files for Bug Reports using Domain Knowledge", "authors": "Ye Xin, Bunescu Razvan, Liu Chang", "year": 2014, "classification": "IR-based bug localization", "tags": ["learn to rank", "dataset"], "links": "https://doi.org/10.1145/2635868.2635874", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "FSE/ESEC", "abstract": "When a new bug report is received, developers usually need to reproduce the bug and perform code reviews to find the cause, a process that can be tedious and time consuming. A tool for ranking all the source files of a project with respect to how likely they are to contain the cause of the bug would enable developers to narrow down their search and potentially could lead to a substantial increase in productivity. This paper introduces an adaptive ranking approach that leverages domain knowledge through functional decompositions of source code files into methods, API descriptions of library components used in the code, the bug-fixing history, and the code change history. Given a bug report, the ranking score of each source file is computed as a weighted combination of an array of features encoding domain knowledge, where the weights are trained automatically on previously solved bug reports using a learning-to-rank technique. We evaluated our system on six large scale open source Java projects, using the before-fix version of the project for every bug report. The experimental results show that the newly introduced learning-to-rank approach significantly outperforms two recent state-of-the-art methods in recommending relevant files for bug reports. In particular, our method makes correct recommendations within the top 10 ranked source files for over 70% of the bug reports in the Eclipse Platform and Tomcat projects.", "datasets": "http://dx.doi.org/10.6084/m9.figshare.951967"}, {"title": "On the Effectiveness of Information Retrieval Based Bug Localization for C Programs", "authors": "Saha Ripon K., Lawall Julia, Khurshid Sarfraz, Perry Dewayne E.", "year": 2014, "classification": "Empirical study", "tags": ["dataset"], "links": "https://doi.org/10.1109/ICSME.2014.38", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICSME", "abstract": "Localizing bugs is important, difficult, and expensive, especially for large software projects. To address this problem, information retrieval (IR) based bug localization has increasingly been used to suggest potential buggy files given a bug report. To date, researchers have proposed a number of IR techniques for bug localization and empirically evaluated them to understand their effectiveness. However, virtually all of the evaluations have been limited to the projects written in object-oriented programming languages, particularly Java. Therefore, the effectiveness of these techniques for other widely used languages such as C is still unknown. In this paper, we create a benchmark dataset consisting of more than 7,500 bug reports from five popular C projects and rigorously evaluate our recently introduced IR-based bug localization tool using this dataset. Our results indicate that although the IR-relevant properties of C and Java programs are different, IR-based bug localization in C software at the file level is overall as effective as in Java software. However, we also find that the recent advance of using program structure information in performing bug localization gives less of a benefit for C software than for Java software.", "datasets": "https://utexas.box.com/icsme2014-dataset"}, {"title": "On the Use of Stack Traces to Improve Text Retrieval-Based Bug Localization", "authors": "Moreno Laura, Treadway John Joseph, Marcus Andrian, Shen Wuwei", "year": 2014, "classification": "IR-based bug localization", "tags": ["stack trace"], "links": "https://doi.org/10.1109/ICSME.2014.37", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICSME", "abstract": "Many bug localization techniques rely on Text Retrieval (TR) models. The most successful approaches have been proven to be the ones combining TR techniques with static analysis, dynamic analysis, and/or software repositories information. Dynamic software analysis and software repositories mining bring a significant overhead, as they require instrumenting and executing the software, and analyzing large amounts of data, respectively. We propose a new static technique, named Lobster (Locating Bugs using Stack Traces and text Retrieval), which is meant to improve TR-based bug localization without the overhead associated with dynamic analysis and repository mining. Specifically, we use the stack traces submitted in a bug report to compute the similarity between their code elements and the source code of a software system. We combine the stack trace based similarity and the textual similarity provided by TR techniques to retrieve code elements relevant to bug reports. We empirically evaluated Lobster using 155 bug reports containing stack traces from 14 open source software systems. We used Lucene, an optimized version of VSM, as baseline of comparison. The results show that, in average, Lobster improves or maintains the effectiveness of Lucene-based bug localization in 82% of the cases.", "datasets": ""}, {"title": "Potential biases in bug localization: do they matter?", "authors": "Kochhar Pavneet Singh, Tian Yuan, Lo David", "year": 2014, "classification": "Empirical study", "tags": ["empirical study"], "links": "https://doi.org/10.1145/2642937.2642997", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ASE", "abstract": "Issue tracking systems are valuable resources during software maintenance activities and contain information about the issues faced during the development of a project as well as after its release. Many projects receive many reports of bugs and it is challenging for developers to manually debug and fix them. To mitigate this problem, past studies have proposed information retrieval (IR)-based bug localization techniques, which takes as input a textual description of a bug stored in an issue tracking system, and returns a list of potentially buggy source code files. These studies often evaluate their effectiveness on issue reports marked as bugs in issue tracking systems, using as ground truth the set of files that are modified in commits that fix each bug. However, there are a number of potential biases that can impact the validity of the results reported in these studies. First, issue reports marked as bugs might not be reports of bugs due to error in the reporting and classification process. Many issue reports are about documentation update, request for improvement, refactoring, code cleanups, etc. Second, bug reports might already explicitly specify the buggy program files and for these reports bug localization techniques are not needed. Third, files that get modified in commits that fix the bugs might not contain the bug. This study investigates the extent these potential biases affect the results of a bug localization technique and whether bug localization researchers need to consider these potential biases when evaluating their solutions. In this paper, we analyse issue reports from three different projects: HTTP-Client, Jackrabbit, and Lucene-Java to examine the impact of above three biases on bug localization. Our results show that one of these biases significantly and substantially impacts bug localization results, while the other two biases have negligible or minor impact.", "datasets": ""}, {"title": "Predicting Effectiveness of IR-Based Bug Localization Techniques", "authors": "Le Tien Duy B., Thung Ferdian, Lo David", "year": 2014, "classification": "Empirical study", "tags": ["effectiveness prediction"], "links": "https://doi.org/10.1109/ISSRE.2014.39", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ISSRE", "abstract": "Recently, many information retrieval (IR) based bug localization approaches have been proposed in the literature. These approaches use information retrieval techniques to process a textual bug report and a collection of source code files to find buggy files. They output a ranked list of files sorted by their likelihood to contain the bug. Recent approaches can achieve reasonable accuracy, however, even a state-of-the-art bug localization tool outputs many ranked lists where buggy files appear very low in the lists. This potentially causes developers to distrust bug localization tools. Parnin and Orso recently conduct a user study and highlight that developers do not find an automated debugging tool useful if they do not find the root cause of a bug early in a ranked list. To address this problem, we build an oracle that can automatically predict whether a ranked list produced by an IR-based bug localization tool is likely to be effective or not. We consider a ranked list to be effective if a buggy file appears in the top-N position of the list. If a ranked list is unlikely to be effective, developers do not need to waste time in checking the recommended files one by one. In such cases, it is better for developers to use traditional debugging methods or request for further information to localize bugs. To build this oracle, our approach extracts features that can be divided into four categories: score features, textual features, topic model features, and metadata features. We build a separate prediction model for each category, and combine them to create a composite prediction model which is used as the oracle. We name our proposed approach APRILE, which stands for Automated Prediction of IR-based Bug Localization's Effectiveness. We have evaluated APRILE to predict the effectiveness of three state-of-the-art IR based bug localization tools on more than three thousands bug reports from AspectJ, Eclipse, and SWT. APRILE can achieve an average precision, recall, and F-measure of at least 70.36%, 66.94%, and 68.03%, respectively. Furthermore, APRILE outperforms a baseline approach by 84.48%, 17.74%, and 31.56% for the AspectJ, Eclipse, and SWT bug reports, respectively.", "datasets": ""}, {"title": "Version history, similar report, and structure: putting them together for improved bug localization", "authors": "Wang Shaowei, Lo David", "year": 2014, "classification": "IR-based bug localization", "tags": ["version history", "similar report", "structure"], "links": "https://doi.org/10.1145/2597008.2597148", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICPC", "abstract": "During the evolution of a software system, a large number of bug reports are submitted. Locating the source code files that need to be fixed to resolve the bugs is a challenging problem. Thus, there is a need for a technique that can automatically figure out these buggy files. A number of bug localization solutions that take in a bug report and output a ranked list of files sorted based on their likelihood to be buggy have been proposed in the literature. However, the accuracy of these tools still need to be improved. In this paper, to address this need, we propose AmaLgam, a new method for locating relevant buggy files that puts together version history, similar reports, and structure. To do this, AmaLgam integrates a bug prediction technique used in Google which analyzes version history, with a bug localization technique named BugLocator which analyzes similar reports from bug report system, and the state-of-the-art bug localization technique BLUiR which considers structure. We perform a large-scale experiment on four open source projects, namely AspectJ, Eclipse, SWT and ZXing to localize more than 3,000 bugs. Compared with a history-aware bug localization solution of Sisman and Kak, our approach achieves a 46.1% improvement in terms of mean average precision (MAP). Compared with BugLocator, our approach achieves a 24.4% improvement in terms of MAP. Compared with BLUiR, our approach achieves a 16.4% improvement in terms of MAP.", "datasets": ""}, {"title": "An incremental update framework for efficient retrieval from software libraries for bug localization", "authors": "Rao Shivani, Medeiros Henry, Kak Avinash", "year": 2013, "classification": "IR-based bug localization", "tags": ["incremental framework", "dataset"], "links": "https://doi.org/10.1109/WCRE.2013.6671281", "CCF": "\u672a\u77e5", "conference": "WCRE", "abstract": "Information Retrieval (IR) based bug localization techniques use a bug reports to query a software repository to retrieve relevant source files. These techniques index the source files in the software repository and train a model which is then queried for retrieval purposes. Much of the current research is focused on improving the retrieval effectiveness of these methods. However, little consideration has been given to the efficiency of such approaches for software repositories that are constantly evolving. As the software repository evolves, the index creation and model learning have to be repeated to ensure accuracy of retrieval for each new bug. In doing so, the query latency may be unreasonably high, and also, re-computing the index and the model for files that did not change is computationally redundant. We propose an incremental update framework to continuously update the index and the model using the changes made at each commit. We demonstrate that the same retrieval accuracy can be achieved but with a fraction of the time needed by current approaches. Our results are based on two basic IR modeling techniques - Vector Space Model (VSM) and Smoothed Unigram Model (SUM). The dataset we used in our validation experiments was created by tracking commit history of AspectJ and JodaTime software libraries over a span of 10 years.", "datasets": "https://engineering.purdue.edu/RVL/Database/moreBugs/"}, {"title": "Assisting code search with automatic Query Reformulation for bug localization", "authors": "Sisman Bunyamin, Kak Avinash C.", "year": 2013, "classification": "Query reformulation", "tags": ["query reformulation", "dataset"], "links": "https://doi.org/10.1109/MSR.2013.6624044", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "MSR", "abstract": "Source code retrieval plays an important role in many software engineering tasks. However, designing a query that can accurately retrieve the relevant software artifacts can be challenging for developers as it requires a certain level of knowledge and experience regarding the code base. This paper demonstrates how the difficulty of designing a proper query can be alleviated through automatic Query Reformulation (QR) - an under-the-hood operation for reformulating a user's query with no additional input from the user. The proposed QR framework works by enriching a user's search query with certain specific additional terms drawn from the highest-ranked artifacts retrieved in response to the initial query. The important point here is that these additional terms injected into a query are those that are deemed to be \"close\" to the original query terms in the source code on the basis of positional proximity. This similarity metric is based on the notion that terms that deal with the same concepts in source code are usually proximal to one another in the same files. We demonstrate the superiority of our QR framework in relation to the QR frameworks well-known in the natural language document retrieval by showing significant improvements in bug localization performance for two large software projects using more than 4,000 queries. ", "datasets": "https://engineering.purdue.edu/RVL/Database/BUGLinks/"}, {"title": "Concept localization using n-gram information retrieval model and control flow graph", "authors": "Jain Nikita, Garg Rashi, Chawla Indu", "year": 2013, "classification": "IR-based bug localization", "tags": ["N-Gram", "concern localization"], "links": "https://doi.org/10.1049/cp.2013.2289", "CCF": "C\u7c7b\u671f\u520a", "conference": "IET", "abstract": "Developing software involves many phases such as designing, coding and testing. Once the software is released, a separate team is responsible for maintaining the software. Nowadays many researchers and users work on Open Source Software to enhance its functionalities and to mould it according to their needs. Most of the time, a user or developer wants to locate a specific feature in software for the purpose of enhancement or removing a fault, which is known as concept localization. Automatic concept localization gives relevant files to the users as per the requirement. We have implemented n-gram, an Information Retrieval model to retrieve the names of the relevant files from the source code and incorporated Control Flow Graph (CFG) which helped us to determine the files encapsulating the functionality, in the correct order. We conducted tests on numerous grounds such as different threshold values (0.4, 0.6 and 0.8), N value (2 and 3) and varying query length. On examination, we obtained recall of 74% and precision of 65% on threshold value of 0.6 using trigram (i.e. n=3). Control Flow Graph significantly contributed in improving the ranking of relevant files.", "datasets": ""}, {"title": "Feature location in source code: a taxonomy and survey", "authors": "Dit Bogdan, Revelle Meghan, Gethers Malcom, Poshyvanyk Denys", "year": 2013, "classification": "Empirical study", "tags": ["dataset"], "links": "https://doi.org/10.1002/smr.567", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Feature location is the activity of identifying an initial location in the source code that implements function-ality in a software system. Many feature location techniques have been introduced that automate some or all of this process, and a comprehensive overview of this large body of work would be beneficial to researchers and practitioners. This paper presents a systematic literature survey of feature location techniques. Eighty-nine articles from 25 venues have been reviewed and classified within the taxonomy in order to organize and structure existing work in the field of feature location. The paper also discusses open issues and defines future directions in the field of feature location.", "datasets": "http://www.cs.wm.edu/semeru/data/benchmarks/"}, {"title": "Improving bug localization using structured information retrieval", "authors": "Saha Ripon K., Lease Matthew, Khurshid Sarfraz, Perry Dewayne E.", "year": 2013, "classification": "IR-based bug localization", "tags": ["structure"], "links": "https://doi.org/10.1109/ASE.2013.6693093", "CCF": "A\u7c7b\u671f\u520a", "conference": "ASE", "abstract": "Locating bugs is important, difficult, and expensive, particularly for large-scale systems. To address this, natural language information retrieval techniques are increasingly being used to suggest potential faulty source files given bug reports. While these techniques are very scalable, in practice their effectiveness remains low in accurately localizing bugs to a small number of files. Our key insight is that structured information retrieval based on code constructs, such as class and method names, enables more accurate bug localization. We present BLUiR, which embodies this insight, requires only the source code and bug reports, and takes advantage of bug similarity data if available. We build BLUiR on a proven, open source IR toolkit that anyone can use. Our work provides a thorough grounding of IR-based bug localization research in fundamental IR theoretical and empirical knowledge and practice. We evaluate BLUiR on four open source projects with approximately 3,400 bugs. Results show that BLUiR matches or outperforms a current state-of-the-art tool across applications considered, even when BLUiR does not use bug similarity data used by the other tool. ", "datasets": ""}, {"title": "It\u2019s not a Bug, it\u2019s a Feature: How Misclassification Impacts Bug Prediction", "authors": "Herzig Kim, Just Sascha, Zeller Andreas", "year": 2013, "classification": "Empirical study", "tags": ["empirical study", "dataset"], "links": "https://doi.org/10.5555/2486788.2486840", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ICSE", "abstract": "This submission presents work submitted and accepted at the International onference on Software Engineering in 2013 [Hj2013]. In empirical software engineering, it has become common to mine historic data to detect where bugs have occurred in the past, or to predict where they will occur in the future. The accuracy of such models depends on the quality of the data. For example, defect prediction models rely on the accuracy of historic data, such as bug reports. Bug reports that refer to any other than corrective development activities may cause code artefacts to be falsely marked as defective. This may have severe consequences for the resulting models and its accuracy. Earlier studies raised concerns about bug reports referring to error unrelated development activities. But how often does such misclassification occur? Further, does it actually impact analysis and prediction models? These are the questions we addressed in this paper. In a manual examination of more than 7,000 issue reports from five open-source projects, we found 33.8% of all bug reports to be misclassified threatening bug prediction models, confusing bugs and features: On average, 39% of files marked as defective actually never had a bug. The presentation will cover causes for issue report misclassification and the result of our study (some newer results not in the paper).", "datasets": "https://www.st.cs.uni-saarland.de//softevo/bugclassify/"}, {"title": "Mining A change history to quickly identify bug locations : A case study of the Eclipse project", "authors": "Tantithamthavorn Chakkrit, Teekavanich Rattamont, Ihara Akinori, Matsumoto Ken Ichi", "year": 2013, "classification": "IR-based bug localization", "tags": ["change history", "empirical study"], "links": "https://doi.org/10.1109/ISSREW.2013.6688888", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ISSRE", "abstract": "In this study, we proposed an approach to mine a change history to improve the bug localization performance. The key idea is that a recently fixed file may be fixed in the near future. We used a combination of textual feature and mining the change history to recommend source code files that are likely to be fixed for a given bug report. First, we adopted the Vector Space Model (VSM) to find relevant source code files that are textually similar to the bug report. Second, we analyzed the change history to identify previously fixed files. We then estimated the fault proneness of these files. Finally, we combined the two scores, from textual similarity and fault proneness, for every source code file. We then recommend developers examine source code files with higher scores. We evaluated our approach based on 1,212 bug reports from the Eclipse Platform and Eclipse JDT. The experimental results show that our proposed approach can improve the bug localization performance and effectively identify buggy files. ", "datasets": ""}, {"title": "Multi-abstraction Concern Localization", "authors": "Le Tien Duy B., Wang Shaowei, Lo David", "year": 2013, "classification": "IR-based bug localization", "tags": ["concern localization", "LDA", "topic model"], "links": "https://doi.org/10.1109/ICSM.2013.48", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICSM", "abstract": "Concern localization refers to the process of locating code units that match a particular textual description. It takes as input textual documents such as bug reports and feature requests and outputs a list of candidate code units that need to be changed to address the bug reports or feature requests. Many information retrieval (IR) based concern localization techniques have been proposed in the literature. These techniques typically represent code units and textual descriptions as a bag of tokens at one level of abstraction, e.g., each token is a word, or each token is a topic. In this work, we propose multi-abstraction concern localization. A code unit and a textual description is represented at multiple abstraction levels. Similarity of a textual description and a code unit, is now made by considering all these abstraction levels. We have evaluated our solution on AspectJ bug reports and feature requests from the iBugs benchmark dataset. The experiment shows that our proposed approach outperforms a baseline approach, in terms of Mean Average Precision, by up to 19.36%.", "datasets": ""}, {"title": "On the Influence of Latent Semantic Analysis Parameterization for Bug Localization", "authors": "Maia Marcelo De Almeida, Costa e Silva Allysson, Silva Ilm\u00e9rio Reis da", "year": 2013, "classification": "Empirical study", "tags": ["empirical study", "LSI"], "links": "https://doi.org/10.22456/2175-2745.31690", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "The bug localization problem has benefited from modern information retrieval techniques, such as Latent Semantic Analysis. There are many factors that influence the quality of results of this approach, such as, stop-words, term-document matrix transformations, dimensionality reduction and filtering criteria of the corpus. In this paper, we study the effect of different combinations for these factors on the impact of the accuracy of the query results in the proposed technique for bug localization. Bugs of three real-world software systems were analyzed with different combinations of input parameters for the LSA technique. Our results suggest that the term-document matrix transformations and filtering criteria of the corpus have major influence in the quality of the result and that the combination of adequate individual parameter values does not necessarily produce the best combination. Furthermore, some general guidance for parameterization of the LSA technique for bug localization could also be suggested from the observed results.", "datasets": ""}, {"title": "On the Relationship between the Vocabulary of Bug Reports and Source Code", "authors": "Moreno Laura, Bandara Wathsala, Haiduc Sonia, Marcus Andrian", "year": 2013, "classification": "Empirical study", "tags": ["empirical study", "dataset"], "links": "https://doi.org/10.1109/ICSM.2013.70", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICSM", "abstract": "Text retrieval (TR) techniques have been widely used to support concept and bug location. When locating bugs, developers often formulate queries based on the bug descriptions. More than that, a large body of research uses bug descriptions to evaluate bug location techniques using TR. The implicit assumption is that the bug descriptions and the relevant source code files share important words. In this paper, we present an empirical study that explores this conjecture. We found that bug reports share more terms with the patched classes than with the other classes in the system. Furthermore, we found that the class names are more likely to share terms with the bug descriptions than other code locations, while more verbose parts of the code (e.g., comments) will share more words. We also found that the shared terms may be better predictors for bug location than some TR techniques. ", "datasets": "http://www.cs.wayne.edu/~severe/era13"}, {"title": "The Impact of Classifier Configuration and Classifier Combination on Bug Localization", "authors": "Thomas Stephen W., Nagappan Meiyappan, Blostein Dorothea, Hassan Ahmed E.", "year": 2013, "classification": "Empirical study", "tags": ["empirical study", "dataset", "LDA", "LSI", "VSM"], "links": "https://doi.org/10.1109/TSE.2013.27", "CCF": "A\u7c7b\u671f\u520a", "conference": "TSE", "abstract": "Bug localization is the task of determining which source code entities are relevant to a bug report. Manual bug localization is labor intensive since developers must consider thousands of source code entities. Current research builds bug localization classifiers, based on information retrieval models, to locate entities that are textually similar to the bug report. Current research, however, does not consider the effect of classifier configuration, i.e., all the parameter values that specify the behavior of a classifier. As such, the effect of each parameter or which parameter values lead to the best performance is unknown. In this paper, we empirically investigate the effectiveness of a large space of classifier configurations, 3,172 in total. Further, we introduce a framework for combining the results of multiple classifier configurations since classifier combination has shown promise in other domains. Through a detailed case study on over 8,000 bug reports from three large-scale projects, we make two main contributions. First, we show that the parameters of a classifier have a significant impact on its performance. Second, we show that combining multiple classifiers-whether those classifiers are hand-picked or randomly chosen relative to intelligently defined subspaces of classifiers-improves the performance of even the best individual classifiers. ", "datasets": "http://sailhome.cs.queensu.ca/replication/sthomas/TSE2013, 2012"}, {"title": "Using Co-change Histories to Improve Bug Localization Performance", "authors": "Tantithamthavorn Chakkrit, Ihara Akinori, Matsumoto Ken-Ichi", "year": 2013, "classification": "IR-based bug localization", "tags": ["change history"], "links": "https://doi.org/10.1109/SNPD.2013.92", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "A large open source software (OSS) project receives many bug reports on a daily basis. Bug localization techniques automatically pinpoint source code fragments that are relevant to a bug report, thus enabling faster correction. Even though many bug localization methods have been introduced, their performance is still not efficient. In this research, we improved on existing bug localization methods by taking into account co-change histories. We conducted experiments on two OSS datasets, the Eclipse SWT 3.1 project and the Android ZXing project. We validated our approach by evaluating effectiveness compared to the state-of-the-art approach Bug Locator. In the Eclipse SWT 3.1 project, our approach reliably identified source code that should be fixed for a bug in 72.46% of the total bugs, while Bug Locator identified only 51.02%. In the Android ZXing project, our approach identified 85.71%, while Bug Locator identified 60%. ", "datasets": ""}, {"title": "Where Should We Fix This Bug? A Two-Phase Recommendation Model", "authors": "Kim Dongsun, Tao Yida, Kim Sunghun, Zeller Andreas", "year": 2013, "classification": "Learning-based bug localization", "tags": ["deep learning"], "links": "https://doi.org/10.1109/TSE.2013.24", "CCF": "A\u7c7b\u671f\u520a", "conference": "TSE", "abstract": "To support developers in debugging and locating bugs, we propose a two-phase prediction model that uses bug reports' contents to suggest the files likely to be fixed. In the first phase, our model checks whether the given bug report contains sufficient information for prediction. If so, the model proceeds to predict files to be fixed, based on the content of the bug report. In other words, our two-phase model \"speaks up\" only if it is confident of making a suggestion for the given bug report; otherwise, it remains silent. In the evaluation on the Mozilla \"Firefox\" and \"Core\" packages, the two-phase model was able to make predictions for almost half of all bug reports; on average, 70 percent of these predictions pointed to the correct files. In addition, we compared the two-phase model with three other prediction models: the Usual Suspects, the one-phase model, and BugScout. The two-phase model manifests the best prediction performance. ", "datasets": ""}, {"title": "A Static Technique for Fault Localization Using Character N-Gram Based Information Retrieval Model", "authors": "Lal Sangeeta, Sureka Ashish", "year": 2012, "classification": "IR-based bug localization", "tags": ["N-Gram"], "links": "https://doi.org/10.1145/2134254.2134274", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Bug or Fault localization is a process of identifying the specific location(s) or region(s) of source code (at various granularity levels such as the directory path, file, method or statement) that is faulty and needs to be modified to repair the defect. Fault localization is a routine task in software maintenance (corrective maintenance). Due to the increasing size and complexity of current software applications, automated solutions for fault localization can significantly reduce human effort and software maintenance cost.\nWe present a technique (which falls into the class of static techniques for bug localization) for fault localization based on a character n-gram based Information Retrieval (IR) model. We frame the problem of bug localization as a relevant document(s) search task for a given query and investigate the application of character-level n-gram based textual features derived from bug reports and source-code file attributes. We implement the proposed IR model and evaluate its performance on dataset downloaded from two popular open-source projects (JBoss and Apache).\nWe conduct a series of experiments to validate our hypothesis and present evidences to demonstrate that the proposed approach is effective. The accuracy of the proposed approach is measured in terms of the standard and commonly used SCORE and MAP (Mean Average Precision) metrics for the task of fault localization. Experimental results reveal that the median value for the SCORE metric for JBoss and Apache dataset is 99.03% and 93.70% respectively. We observe that for 16.16% of the bug reports in the JBoss dataset and for 10.67% of the bug reports in the Apache dataset, the average precision value (computed at all recall levels) is between 0.9 and 1.0.", "datasets": ""}, {"title": "Combining lexical and structural information for static bug localisation", "authors": "Shao Peng, Atkison Travis, Kraft Nicholas A., Smith Randy K.", "year": 2012, "classification": "IR-based bug localization", "tags": ["call dependency", "LSI"], "links": "https://doi.org/10.1504/IJCAT.2012.048208", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "IJCAT", "abstract": "In bug localisation a developer uses information about a bug present in a software system to locate the source code elements that must be modified to correct the bug. Researchers have developed static bug localisation techniques using Information Retrieval techniques such as Latent Semantic Indexing (LSI) to model lexical information from source code. In this paper we present a new technique, LSICG, that combines LSI to model lexical information and call graphs to model structural information. A case study of 21 bugs in Rhino demonstrates that our technique provides improved performance compared to LSI alone.", "datasets": ""}, {"title": "Incorporating version histories in Information Retrieval based bug localization", "authors": "Sisman Bunyamin, Kak Avinash C.", "year": 2012, "classification": "IR-based bug localization", "tags": ["version history"], "links": "https://doi.org/10.1109/MSR.2012.6224299", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "MSR", "abstract": "Fast and accurate localization of software defects continues to be a difficult problem since defects can emanate from a large variety of sources and can often be intricate in nature. In this paper, we show how version histories of a software project can be used to estimate a prior probability distribution for defect proneness associated with the files in a given version of the project. Subsequently, these priors are used in an IR (Information Retrieval) framework to determine the posterior probability of a file being the cause of a bug. We first present two models to estimate the priors, one from the defect histories and the other from the modification histories, with both types of histories as stored in the versioning tools. Referring to these as the base models, we then extend them by incorporating a temporal decay into the estimation of the priors. We show that by just including the base models, the mean average precision (MAP) for bug localization improves by as much as 30%. And when we also factor in the time decay in the estimates of the priors, the improvements in MAP can be as large as 80%. ", "datasets": ""}, {"title": "Locating Source Code to Be Fixed Based on Initial Bug Reports - A Case Study on the Eclipse Project", "authors": "Bangcharoensap Phiradet, Ihara Akinori, Kamei Yasutaka, Matsumoto Ken Ichi", "year": 2012, "classification": "IR-based bug localization", "tags": ["change history"], "links": "https://doi.org/10.1109/IWESEP.2012.14", "CCF": "\u672a\u77e5", "conference": "WESEP", "abstract": "In most software development, a Bug Tracking System is used to improve software quality. Based on bug reports managed by the bug tracking system, triagers who assign a bug to fixers and fixers need to pinpoint buggy files that should be fixed. However if triagers do not know the details of the buggy file, it is difficult to select an appropriate fixer. If fixers can identify the buggy files, they can fix the bug in a short time. In this paper, we propose a method to quickly locate the buggy file in a source code repository using 3 approaches, text mining, code mining, and change history mining to rank files that may be causing bugs. (1) The text mining approach ranks files based on the textual similarity between a bug report and source code. (2) The code mining approach ranks files based on prediction of the fault-prone module using source code product metrics. (3) The change history mining approach ranks files based on prediction of the fault-prone module using change process metrics. Using Eclipse platform project data, our proposed model gains around 20% in TOP1 prediction. This result means that the buggy files are ranked first in 20% of bug reports. Furthermore, bug reports that consist of a short description and many specific words easily identify and locate the buggy file.", "datasets": ""}, {"title": "Using Bug Report Similarity to Enhance Bug Localisation", "authors": "Davies Steven, Roper Marc, Wood Murray", "year": 2012, "classification": "IR-based bug localization", "tags": ["similar report"], "links": "https://doi.org/10.1109/WCRE.2012.22", "CCF": "\u672a\u77e5", "conference": "WCRE", "abstract": "Bug localisation techniques are proposed as a method to reduce the time developers spend on maintenance, allowing them to quickly find source code relevant to a bug. Some techniques are based on information retrieval methods, treating the source code as a corpus and the bug report as a query. While these have shown success, there remain a number of little-exploited additional sources of information which could enhance the techniques, including the textual similarity between bug reports themselves. Based on successful results in detecting duplicate bug reports, this work asks: if duplicate bugs reports, which by definition are fixed in the same source location, can be detected through the use of similar language, can bugs which are in the same location but not duplicates be detected in the same way? A technique using this information is implemented and evaluated on 372 bugs across 4 projects, and is found to improve performance on all projects. In particular, the technique increases the number of bugs where the first relevant method presented to developers is the first result from 6 to 27, and those in the top-10 from 50 to 57, showing that it can be successfully used to enhance existing bug localisation techniques. ", "datasets": ""}, {"title": "Where should the bugs be fixed? More accurate information retrieval-based bug localization based on bug reports", "authors": "Zhou Jian, Zhang Hongyu, Lo David", "year": 2012, "classification": "IR-based bug localization", "tags": ["dataset", "rVSM", "similar report"], "links": "https://doi.org/10.1109/ICSE.2012.6227210", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ICSE", "abstract": "For a large and evolving software system, the project team could receive a large number of bug reports. Locating the source code files that need to be changed in order to fix the bugs is a challenging task. Once a bug report is received, it is desirable to automatically point out to the files that developers should change in order to fix the bug. In this paper, we propose BugLocator, an information retrieval based method for locating the relevant files for fixing a bug. BugLocator ranks all files based on the textual similarity between the initial bug report and the source code using a revised Vector Space Model (rVSM), taking into consideration information about similar bugs that have been fixed before. We perform large-scale experiments on four open source projects to localize more than 3,000 bugs. The results show that BugLocator can effectively locate the files where the bugs should be fixed. For example, relevant buggy files for 62.60% Eclipse 3.1 bugs are ranked in the top ten among 12,863 files. Our experiments also show that BugLocator outperforms existing state-of-the-art bug localization methods.", "datasets": "http://code.google.com/p/bugcenter"}, {"title": "A topic-based approach for narrowing the search space of buggy files from a bug report", "authors": "Xiao Yan, Keung Jacky, Mi Qing, Bennin Kwabena E.", "year": 2011, "classification": "IR-based bug localization", "tags": ["search space minimization", "topic model"], "links": "https://doi.org/10.1109/APSEC.2017.40", "CCF": "A\u7c7b\u671f\u520a", "conference": "ASE", "abstract": "Background: Localizing buggy files automatically speeds up the process of bug fixing so as to improve the efficiency and productivity of software quality teams. There are other useful semantic information available in bug reports and source code, but are mostly underutilized by existing bug localization approaches. Aims: We propose DeepLocator, a novel deep learning based model to improve the performance of bug localization by making full use of semantic information. Method: DeepLocator is composed of an enhanced CNN (Convolutional Neural Network) proposed in this study considering bug-fixing experience, together with a new rTF-IDuF method and pretrained word2vec technique. DeepLocator is then evaluated on over 18,500 bug reports extracted from AspectJ, Eclipse, JDT, SWT and Tomcat projects. Results: The experimental results show that DeepLocator achieves 9.77% to 26.65% higher Fmeasure than the conventional CNN and 3.8% higher MAP than a state-of-the-art method HyLoc using less computation time. Conclusion: DeepLocator is capable of automatically connecting bug reports to the corresponding buggy files and successfully achieves better performance based on a deep understanding of semantics in bug reports and source code.", "datasets": ""}, {"title": "Combining information retrieval modules and structural information for source code bug localization and feature location", "authors": "Shao Peng , K. Smith Randy, Chair Committee, Kraft Nicholas A. , Atkison Travis, Carver Jeffrey C., Parrish Allen S. ", "year": 2011, "classification": "IR-based bug localization", "tags": ["feature identification", "LSI", "structure"], "links": "https://ir.ua.edu/handle/123456789/1238", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Bug localization and feature location in source code are software evolution tasks in which developers use information about a bug or feature present in a software system to locate the source code elements, such as classes or methods. These classes or methods must be modified either to correct the bug or implement a feature. Automating bug localization and feature location are necessary due to the size and complexity of modern software systems. Recently, researchers have developed static bug localization and feature location techniques using information retrieval techniques, such as latent semantic indexing (LSI), to model lexical information, such as identifiers and comments, from source code. This research presents a new technique, LSICG, which combines LSI modeling lexical information and call graphs to modeling structural information. The output is a list of methods ranked in descending order by likelihood of requiring modification to correct the bug or implement the feature under consideration. Three case studies including comparison of LSI and LSICG at method level and class level of granularity on 25 features in JavaHMO, 35 bugs in Rhino, 3 features and 6 bugs in jEdit demonstrate that The LSICG technique provides improved performance compared to LSI alone.", "datasets": ""}, {"title": "Concern Localization using Information Retrieval: An Empirical Study on Linux Kernel", "authors": "Wang Shaowei, Lo David, Xing Zhenchang, Jiang Lingxiao", "year": 2011, "classification": "Empirical study", "tags": ["empirical study", "concern localization"], "links": "https://doi.org/10.1109/WCRE.2011.72", "CCF": "\u672a\u77e5", "conference": "WCRE", "abstract": "Many software maintenance activities need to find code units (functions, files, etc.) that implement a certain concern (features, bugs, etc.). To facilitate such activities, many approaches have been proposed to automatically link code units with concerns described in natural languages, which are termed as concern localization and often employ Information Retrieval (IR) techniques. There has not been a study that evaluates and compares the effectiveness of latest IR techniques on a large dataset. This study fills this gap by investigating ten IR techniques, some of which are new and have not been used for concern localization, on a Linux kernel dataset. The Linux kernel dataset contains more than 1,500 concerns that are linked to over 85,000 C functions. We have evaluated the effectiveness of the ten techniques on recovering the links between the concerns and the implementing functions and ranked the IR techniques based on their precisions on concern localization. ", "datasets": ""}, {"title": "Extending Bug Localization Using Information Retrieval and Code Clone Location Techniques", "authors": "Beard Matthew", "year": 2011, "classification": "IR-based bug localization", "tags": ["code clone", "concern localization", "feature identification"], "links": "https://doi.org/10.1109/WCRE.2011.61", "CCF": "\u672a\u77e5", "conference": "WCRE", "abstract": "Bug localization involves the use of information about a bug to assist in locating sections of code that must be modified to fix the bug. Such a task can involve a considerable amount of time and effort on the part of software developers and/or maintainers. Recently, several automated bug localization techniques based on information retrieval (IR) models have been developed to speed the process of bug localization. Another code analysis technique involves locating duplicated sections of code in software projects, called code clones. We examine the application of code clone location techniques in the context of bug localization. We attempt to determine the advantages of extending existing code clone location techniques through the inclusion of IR models in the analysis process. We also examine a technique for extending the use of bug logging repositories and version control systems by analyzing the two using IR techniques. ", "datasets": ""}, {"title": "Measuring the Accuracy of Information Retrieval Based Bug Localization Techniques", "authors": "Beard Matthew, Kraft Nicholas, Etzkorn Letha, Lukins Stacy", "year": 2011, "classification": "Empirical study", "tags": ["evaluation metrics", "feature identification", "LDA", "LSI"], "links": "https://doi.org/10.1109/WCRE.2011.23", "CCF": "\u672a\u77e5", "conference": "WCRE", "abstract": "Bug localization involves using information about a bug to locate affected code sections. Several automated bug localization techniques based on information retrieval (IR) models have been constructed recently. The \"gold standard\" of measuring an IR technique's accuracy considers the technique's ability to locate a \"first relevant method.\" However, the question remains - does finding this single method enable the location of a complete set of affected methods? Previous arguments assume this to be true, however, few analyses of this assumption have been performed. In this paper, we perform a case study to test the reliability of this \"gold standard\" assumption. To further measure IR accuracy in the context of bug localization, we analyze the relevance of the IR model's \"first method returned.\" We use various structural analysis techniques to extend relevant methods located by IR techniques and determine accuracy and reliability of these assumptions. ", "datasets": ""}, {"title": "Retrieval from software libraries for bug localization: a comparative study of generic and composite text models", "authors": "Rao Shivani, Kak Avinash", "year": 2011, "classification": "Empirical study", "tags": ["empirical study", "LDA", "LSI"], "links": "https://doi.org/10.1145/1985441.1985451", "CCF": "C\u7c7b\u4f1a\u8bae", "conference": "MSR", "abstract": "From the standpoint of retrieval from large software libraries for the purpose of bug localization, we compare five generic text models and certain composite variations thereof. The generic models are: the Unigram Model (UM), the Vector Space Model (VSM), the Latent Semantic Analysis Model (LSA), the Latent Dirichlet Allocation Model (LDA), and the Cluster Based Document Model (CBDM). The task is to locate the files that are relevant to a bug reported in the form of a textual description by a software developer. We use for our study iBUGS, a benchmarked bug localization dataset with 75 KLOC and a large number of bugs (291). A major conclusion of our comparative study is that simple text models such as UM and VSM are more effective at correctly retrieving the relevant files from a library as compared to the more sophisticated models such as LDA. The retrieval effectiveness for the various models was measured using the following two metrics: (1) Mean Average Precision; and (2) Rank-based metrics. Using the SCORE metric, we also compare the retrieval effectiveness of the models in our study with some other bug localization tools.", "datasets": ""}, {"title": "Augmented bug localization using past bug information", "authors": "Nichols Brent D.", "year": 2010, "classification": "IR-based bug localization", "tags": ["LSI", "version history"], "links": "https://doi.org/10.1145/1900008.1900090", "CCF": "\u672a\u77e5", "conference": "\u5176\u4ed6", "abstract": "Traditional bug localization techniques involve a developer using his or her knowledge of the software system to locate bugs in source code. Various automated techniques simulate knowledge of the system using source code retrieval models such as latent semantic indexing (LSI) and latent Dirichlet allocation (LDA). While these methods do an adequate job, they do not make use of another wealth of information stored in the form of past bug reports. In this paper, I present an extension to the LSI model for bug localization in which the information stored in past bug reports augments the LSI model of bug localization. I describe the details of implementing this process along with the novel patch cartographer tool that is necessary for its execution. Presented along with this description is a pair of case studies verifying the effectiveness of the patch cartographer and process respectively. Results show that the patch cartographer indeed correctly identifies affected methods from a patch file. Additionally, the study of the augmented process shows significant improvement in performance compared to LSI alone.", "datasets": ""}, {"title": "Bug localization using latent Dirichlet allocation", "authors": "Lukins Stacy K., Kraft Nicholas A., Etzkorn Letha H.", "year": 2010, "classification": "IR-based bug localization", "tags": ["LDA"], "links": "https://doi.org/10.1016/j.infsof.2010.04.002", "CCF": "B\u7c7b\u671f\u520a", "conference": "IST", "abstract": "Context: Some recent static techniques for automatic bug localization have been built around modern information retrieval (IR) models such as latent semantic indexing (LSI). Latent Dirichlet allocation (LDA) is a generative statistical model that has significant advantages, in modularity and extensibility, over both LSI and probabilistic LSI (pLSI). Moreover, LDA has been shown effective in topic model based information retrieval. In this paper, we present a static LDA-based technique for automatic bug localization and evaluate its effectiveness. Objective: We evaluate the accuracy and scalability of the LDA-based technique and investigate whether it is suitable for use with open-source software systems of varying size, including those developed using agile methods. Method: We present five case studies designed to determine the accuracy and scalability of the LDA-based technique, as well as its relationships to software system size and to source code stability. The studies examine over 300 bugs across more than 25 iterations of three software systems. Results: The results of the studies show that the LDA-based technique maintains sufficient accuracy across all bugs in a single iteration of a software system and is scalable to a large number of bugs across multiple revisions of two software systems. The results of the studies also indicate that the accuracy of the LDA-based technique is not affected by the size of the subject software system or by the stability of its source code base. Conclusion: We conclude that an effective static technique for automatic bug localization can be built around LDA. We also conclude that there is no significant relationship between the accuracy of the LDA-based technique and the size of the subject software system or the stability of its source code base. Thus, the LDA-based technique is widely applicable. ", "datasets": ""}, {"title": "Bug Localization Using Revision Log Analysis and Open Bug Repository Text Categorization", "authors": "Moin Amir H., Khansari Mohammad", "year": 2010, "classification": "IR-based bug localization", "tags": ["version history", "SVM"], "links": "https://doi.org/10.1007/978-3-642-13244-5_15", "CCF": "\u672a\u77e5", "conference": "OSS", "abstract": "In this paper, we present a new approach to localize a bug in the software source file hierarchy. The proposed approach uses log files of the revision control system and bug reports information in open bug repository of open source projects to train a Support Vector Machine (SVM) classifier. Our approach employs textual information in summary and description of bugs reported to the bug repository, in order to form machine learning features. The class labels are revision paths of fixed issues, as recorded in the log file of the revision control system. Given an unseen bug instance, the trained classifier can predict which part of the software source file hierarchy (revision path) is more likely to be related to this issue. Experimental results on more than 2000 bug reports of \u2018UI\u2019component of the Eclipse JDT project from the initiation date of the project until November 24, 2009 (about 8 years) using this approach, show weighted precision and recall values of about 98% on average.", "datasets": ""}, {"title": "Source Code Retrieval for Bug Localization Using Latent Dirichlet Allocation", "authors": "Lukins Stacy K., Kraft Nicholas A., Etzkorn Letha H.", "year": 2008, "classification": "IR-based bug localization", "tags": ["LDA"], "links": "https://doi.org/10.1109/WCRE.2008.33", "CCF": "\u672a\u77e5", "conference": "WCRE", "abstract": "In bug localization, a developer uses information about a bug to locate the portion of the source code to modify to correct the bug. Developers expend considerable effort performing this task. Some recent static techniques for automatic bug localization have been built around modern information retrieval (IR) models such as latent semantic indexing (LSI); however, latent Dirichlet allocation (LDA), a modular and extensible IR model, has significant advantages over both LSI and probabilistic LSI (pLSI). In this paper we present an LDA-based static technique for automating bug localization. We describe the implementation of our technique and three case studies that measure its effectiveness. For two of the case studies we directly compare our results to those from similar studies performed using LSI. The results demonstrate our LDA-based technique performs at least as well as the LSI-based techniques for all bugs and performs better, often significantly so, than the LSI-based techniques for most bugs.", "datasets": ""}, {"title": "Extraction of bug localization benchmarks from history", "authors": "Dallmeier Valentin, Zimmermann Thomas", "year": 2007, "classification": "Datasets", "tags": ["dataset"], "links": "https://doi.org/10.1145/1321631.1321702", "CCF": "A\u7c7b\u4f1a\u8bae", "conference": "ASE", "abstract": "Researchers have proposed a number of tools for automatic bug localization. Given a program and a description of the failure, such tools pinpoint a set of statements that are most likely to contain the bug. Evaluating bug localization tools is a difficult task because existing benchmarks are limited in size of subjects and number of bugs. In this paper we present iBUGS, an approach that semiautomatically extracts benchmarks for bug localization from the history of a project. For ASPECTJ, we extracted 369 bugs, 223 out of these had associated test cases. We demonstrate the relevance of our dataset with a case study on the bug localization tool AMPLE. ", "datasets": "https://www.st.cs.uni-saarland.de//ibugs/"}, {"title": "Feature Location Using Probabilistic Ranking of Methods Based on Execution Scenarios and Information Retrieval", "authors": "Poshyvanyk Denys, Gu\u00e9h\u00e9neuc Yann Ga\u00ebl, Marcus Andrian, Antoniol Giuliano, Rajlich V\u00e1clav", "year": 2007, "classification": "IR-based bug localization", "tags": ["feature identification", "probabilistic ranking", "LSI"], "links": "https://doi.org/10.1109/TSE.2007.1016", "CCF": "A\u7c7b\u671f\u520a", "conference": "TSE", "abstract": "This paper recasts the problem of feature location in source code as a decision-making problem in the presence of uncertainty. The solution to the problem is formulated as a combination of the opinions of different experts. The experts in this work are two existing techniques for feature location: a scenario-based probabilistic ranking of events and an information-retrieval-based technique that uses latent semantic indexing. The combination of these two experts is empirically evaluated through several case studies, which use the source code of the Mozilla Web browser and the Eclipse integrated development environment. The results show that the combination of experts significantly improves the effectiveness of feature location as compared to each of the experts used independently", "datasets": ""}, {"title": "Combining Probabilistic Ranking and Latent Semantic Indexing for Feature Identification", "authors": "Poshyvanyk Denys, Gu\u00e9h\u00e9neuc Yann Ga\u00ebl, Marcus Andrian, Antoniol Giuliano, Rajlich V\u00e1clav", "year": 2006, "classification": "IR-based bug localization", "tags": ["feature identification", "probabilistic ranking", "LSI"], "links": "https://doi.org/10.1109/ICPC.2006.17", "CCF": "B\u7c7b\u4f1a\u8bae", "conference": "ICPC", "abstract": "The paper recasts the problem of feature location in source code as a decision-making problem in the presence of uncertainty. The main contribution consists in the combination of two existing techniques for feature location in source code. Both techniques provide a set of ranked facts from the software, as result to the feature identification problem. One of the techniques is based on a scenario based probabilistic ranking of events observed while executing a program under given scenarios. The other technique is defined as an information retrieval task, based on the latent semantic indexing of the source code. We show the viability and effectiveness of the combined technique with two case studies. A first case study is a replication of feature identification in Mozilla, which allows us to directly compare the results with previously published data. The other case study is a bug location problem in Mozilla. The results show that the combined technique improves feature identification significantly with respect to each technique used independently", "datasets": ""}]